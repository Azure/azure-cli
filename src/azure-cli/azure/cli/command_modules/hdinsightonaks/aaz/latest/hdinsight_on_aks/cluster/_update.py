# --------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
#
# Code generated by aaz-dev-tools
# --------------------------------------------------------------------------------------------

# pylint: skip-file
# flake8: noqa

from azure.cli.core.aaz import *


@register_command(
    "hdinsight-on-aks cluster update",
)
class Update(AAZCommand):
    """Update a cluster.

    :example: Update a cluster service-config.
        az hdinsight-on-aks cluster update -n {clusterName} --cluster-pool-name {poolName} -g {RG} -service-configs {"[{service-name:yarn-service,configs:[{component:hadoop-config-client,files:[{file-name:yarn-site.xml,values:{yarn.nodemanager.resource.memory-mb:33333}}]}]}]"}
    """

    _aaz_info = {
        "version": "2024-05-01",
        "resources": [
            ["mgmt-plane", "/subscriptions/{}/resourcegroups/{}/providers/microsoft.hdinsight/clusterpools/{}/clusters/{}", "2024-05-01"],
        ]
    }

    AZ_SUPPORT_NO_WAIT = True

    AZ_SUPPORT_GENERIC_UPDATE = True

    def _handler(self, command_args):
        super()._handler(command_args)
        return self.build_lro_poller(self._execute_operations, self._output)

    _args_schema = None

    @classmethod
    def _build_arguments_schema(cls, *args, **kwargs):
        if cls._args_schema is not None:
            return cls._args_schema
        cls._args_schema = super()._build_arguments_schema(*args, **kwargs)

        # define Arg Group ""

        _args_schema = cls._args_schema
        _args_schema.cluster_name = AAZStrArg(
            options=["-n", "--name", "--cluster-name"],
            help="The name of the HDInsight cluster.",
            required=True,
            id_part="child_name_1",
        )
        _args_schema.cluster_pool_name = AAZStrArg(
            options=["--cluster-pool-name"],
            help="The name of the cluster pool.",
            required=True,
            id_part="name",
        )
        _args_schema.resource_group = AAZResourceGroupNameArg(
            required=True,
        )

        # define Arg Group "ApplicationLogs"

        _args_schema = cls._args_schema
        _args_schema.application_log_std_error_enabled = AAZBoolArg(
            options=["--enable-log-std-error", "--application-log-std-error-enabled"],
            arg_group="ApplicationLogs",
            help="True if application standard error is enabled, otherwise false.",
            nullable=True,
        )
        _args_schema.application_log_std_out_enabled = AAZBoolArg(
            options=["--enable-log-std-out", "--application-log-std-out-enabled"],
            arg_group="ApplicationLogs",
            help="True if application standard out is enabled, otherwise false.",
            nullable=True,
        )

        # define Arg Group "AutoscaleLoadBased"

        _args_schema = cls._args_schema
        _args_schema.loadbased_config_cooldown_period = AAZIntArg(
            options=["--cooldown-period", "--loadbased-config-cooldown-period"],
            arg_group="AutoscaleLoadBased",
            help="This is a cool down period, this is a time period in seconds, which determines the amount of time that must elapse between a scaling activity started by a rule and the start of the next scaling activity, regardless of the rule that triggers it. The default value is 300 seconds.",
            nullable=True,
        )
        _args_schema.loadbased_config_max_nodes = AAZIntArg(
            options=["--loadbased-max-nodes", "--loadbased-config-max-nodes"],
            arg_group="AutoscaleLoadBased",
            help="User needs to set the maximum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.",
        )
        _args_schema.loadbased_config_min_nodes = AAZIntArg(
            options=["--loadbased-min-nodes", "--loadbased-config-min-nodes"],
            arg_group="AutoscaleLoadBased",
            help="User needs to set the minimum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.",
        )
        _args_schema.loadbased_config_poll_interval = AAZIntArg(
            options=["--loadbased-interval", "--loadbased-config-poll-interval"],
            arg_group="AutoscaleLoadBased",
            help="User can specify the poll interval, this is the time period (in seconds) after which scaling metrics are polled for triggering a scaling operation.",
            nullable=True,
        )
        _args_schema.loadbased_config_scaling_rules = AAZListArg(
            options=["--loadbased-rules", "--loadbased-config-scaling-rules"],
            arg_group="AutoscaleLoadBased",
            help="The scaling rules.",
        )

        loadbased_config_scaling_rules = cls._args_schema.loadbased_config_scaling_rules
        loadbased_config_scaling_rules.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.loadbased_config_scaling_rules.Element
        _element.action_type = AAZStrArg(
            options=["action-type"],
            help="The action type.",
            enum={"scaledown": "scaledown", "scaleup": "scaleup"},
        )
        _element.comparison_rule = AAZObjectArg(
            options=["comparison-rule"],
            help="The comparison rule.",
        )
        _element.evaluation_count = AAZIntArg(
            options=["evaluation-count"],
            help="This is an evaluation count for a scaling condition, the number of times a trigger condition should be successful, before scaling activity is triggered.",
        )
        _element.scaling_metric = AAZStrArg(
            options=["scaling-metric"],
            help="Metrics name for individual workloads. For example: cpu",
        )

        comparison_rule = cls._args_schema.loadbased_config_scaling_rules.Element.comparison_rule
        comparison_rule.operator = AAZStrArg(
            options=["operator"],
            help="The comparison operator.",
            enum={"greaterThan": "greaterThan", "greaterThanOrEqual": "greaterThanOrEqual", "lessThan": "lessThan", "lessThanOrEqual": "lessThanOrEqual"},
        )
        comparison_rule.threshold = AAZFloatArg(
            options=["threshold"],
            help="Threshold setting.",
        )

        # define Arg Group "AutoscaleScheduleBased"

        _args_schema = cls._args_schema
        _args_schema.schedule_based_config_default_count = AAZIntArg(
            options=["--schedule-default-count", "--schedule-based-config-default-count"],
            arg_group="AutoscaleScheduleBased",
            help="Setting default node count of current schedule configuration. Default node count specifies the number of nodes which are default when an specified scaling operation is executed (scale up/scale down)",
        )
        _args_schema.schedule_based_config_schedule = AAZListArg(
            options=["--schedule-schedules", "--schedule-based-config-schedule"],
            arg_group="AutoscaleScheduleBased",
            help="This specifies the schedules where scheduled based Autoscale to be enabled, the user has a choice to set multiple rules within the schedule across days and times (start/end).",
        )
        _args_schema.schedule_based_config_time_zone = AAZStrArg(
            options=["--schedule-time-zone", "--schedule-based-config-time-zone"],
            arg_group="AutoscaleScheduleBased",
            help="User has to specify the timezone on which the schedule has to be set for schedule based autoscale configuration.",
        )

        schedule_based_config_schedule = cls._args_schema.schedule_based_config_schedule
        schedule_based_config_schedule.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.schedule_based_config_schedule.Element
        _element.count = AAZIntArg(
            options=["count"],
            help="User has to set the node count anticipated at end of the scaling operation of the set current schedule configuration, format is integer.",
        )
        _element.days = AAZListArg(
            options=["days"],
            help="User has to set the days where schedule has to be set for autoscale operation.",
        )
        _element.end_time = AAZStrArg(
            options=["end-time"],
            help="User has to set the end time of current schedule configuration, format like 10:30 (HH:MM).",
            fmt=AAZStrArgFormat(
                pattern="^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$",
            ),
        )
        _element.start_time = AAZStrArg(
            options=["start-time"],
            help="User has to set the start time of current schedule configuration, format like 10:30 (HH:MM).",
            fmt=AAZStrArgFormat(
                pattern="^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$",
            ),
        )

        days = cls._args_schema.schedule_based_config_schedule.Element.days
        days.Element = AAZStrArg(
            nullable=True,
            enum={"Friday": "Friday", "Monday": "Monday", "Saturday": "Saturday", "Sunday": "Sunday", "Thursday": "Thursday", "Tuesday": "Tuesday", "Wednesday": "Wednesday"},
        )

        # define Arg Group "ClusterProfile"

        _args_schema = cls._args_schema
        _args_schema.authorization_group_id = AAZListArg(
            options=["--authorization-group-id"],
            arg_group="ClusterProfile",
            help="AAD group Ids authorized for data plane access.",
            nullable=True,
        )
        _args_schema.authorization_user_id = AAZListArg(
            options=["--authorization-user-id"],
            arg_group="ClusterProfile",
            help="AAD user Ids authorized for data plane access.",
            nullable=True,
        )
        _args_schema.autoscale_profile_type = AAZStrArg(
            options=["--autoscale-profile-type"],
            arg_group="ClusterProfile",
            help="User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.",
            nullable=True,
            enum={"LoadBased": "LoadBased", "ScheduleBased": "ScheduleBased"},
        )
        _args_schema.enable_autoscale = AAZBoolArg(
            options=["--enable-autoscale"],
            arg_group="ClusterProfile",
            help="This indicates whether auto scale is enabled on HDInsight on AKS cluster.",
        )
        _args_schema.autoscale_profile_graceful_decommission_timeout = AAZIntArg(
            options=["--decommission-time", "--autoscale-profile-graceful-decommission-timeout"],
            arg_group="ClusterProfile",
            help="This property is for graceful decommission timeout; It has a default setting of 3600 seconds before forced shutdown takes place. This is the maximal time to wait for running containers and applications to complete before transition a DECOMMISSIONING node into DECOMMISSIONED. The default value is 3600 seconds. Negative value (like -1) is handled as infinite timeout.",
            nullable=True,
        )
        _args_schema.cluster_version = AAZStrArg(
            options=["--cluster-version"],
            arg_group="ClusterProfile",
            help="Version with 3/4 part.",
            fmt=AAZStrArgFormat(
                pattern="^(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})(?:\.(0|[1-9][0-9]{0,18}))?$",
            ),
        )
        _args_schema.assigned_identity_client_id = AAZStrArg(
            options=["--msi-client-id", "--assigned-identity-client-id"],
            arg_group="ClusterProfile",
            help="ClientId of the MSI.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _args_schema.assigned_identity_object_id = AAZStrArg(
            options=["--msi-object-id", "--assigned-identity-object-id"],
            arg_group="ClusterProfile",
            help="ObjectId of the MSI.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _args_schema.assigned_identity_id = AAZResourceIdArg(
            options=["--msi-id", "--assigned-identity-id"],
            arg_group="ClusterProfile",
            help="ResourceId of the MSI.",
        )
        _args_schema.kafka_profile = AAZObjectArg(
            options=["--kafka-profile"],
            arg_group="ClusterProfile",
            help="Kafka cluster profile.",
            nullable=True,
        )
        _args_schema.llap_profile = AAZFreeFormDictArg(
            options=["--llap-profile"],
            arg_group="ClusterProfile",
            help="LLAP cluster profile.",
            nullable=True,
        )
        _args_schema.enable_log_analytics = AAZBoolArg(
            options=["--enable-log-analytics"],
            arg_group="ClusterProfile",
            help="True if log analytics is enabled for the cluster, otherwise false.",
        )
        _args_schema.oss_version = AAZStrArg(
            options=["--oss-version"],
            arg_group="ClusterProfile",
            help="Version with three part.",
            fmt=AAZStrArgFormat(
                pattern="^(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})$",
            ),
        )
        _args_schema.ranger_plugin_profile = AAZObjectArg(
            options=["--ranger-plugin-profile"],
            arg_group="ClusterProfile",
            help="Cluster Ranger plugin profile.",
            nullable=True,
        )
        _args_schema.ranger_profile = AAZObjectArg(
            options=["--ranger-profile"],
            arg_group="ClusterProfile",
            help="The ranger cluster profile.",
            nullable=True,
        )
        _args_schema.script_action_profiles = AAZListArg(
            options=["--script-action-profiles"],
            arg_group="ClusterProfile",
            help="The script action profile list.",
            nullable=True,
        )
        _args_schema.service_configs_profiles = AAZListArg(
            options=["--service-configs", "--service-configs-profiles"],
            arg_group="ClusterProfile",
            help="The service configs profiles.",
            nullable=True,
        )
        _args_schema.spark_storage_url = AAZStrArg(
            options=["--spark-storage-url"],
            arg_group="ClusterProfile",
            help="The default storage URL.",
            nullable=True,
        )
        _args_schema.user_plugins_spec = AAZObjectArg(
            options=["--user-plugins-spec"],
            arg_group="ClusterProfile",
            help="Spark user plugins spec",
            nullable=True,
        )
        _args_schema.ssh_profile_count = AAZIntArg(
            options=["--ssh-profile-count"],
            arg_group="ClusterProfile",
            help="Number of ssh pods per cluster.",
            fmt=AAZIntArgFormat(
                maximum=5,
                minimum=0,
            ),
        )
        _args_schema.stub_profile = AAZFreeFormDictArg(
            options=["--stub-profile"],
            arg_group="ClusterProfile",
            help="Stub cluster profile.",
            nullable=True,
        )

        authorization_group_id = cls._args_schema.authorization_group_id
        authorization_group_id.Element = AAZStrArg(
            nullable=True,
        )

        authorization_user_id = cls._args_schema.authorization_user_id
        authorization_user_id.Element = AAZStrArg(
            nullable=True,
        )

        kafka_profile = cls._args_schema.kafka_profile
        kafka_profile.disk_storage = AAZObjectArg(
            options=["disk-storage"],
            help="Kafka disk storage profile.",
        )
        kafka_profile.enable_k_raft = AAZBoolArg(
            options=["enable-k-raft"],
            help="Expose Kafka cluster in KRaft mode.",
            nullable=True,
        )
        kafka_profile.enable_public_endpoints = AAZBoolArg(
            options=["enable-public-endpoints"],
            help="Expose worker nodes as public endpoints.",
            nullable=True,
        )
        kafka_profile.remote_storage_uri = AAZStrArg(
            options=["remote-storage-uri"],
            help="Fully qualified path of Azure Storage container used for Tiered Storage.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^(https?|abfss?):\/\/[^/]+(?:\/|$)",
            ),
        )

        disk_storage = cls._args_schema.kafka_profile.disk_storage
        disk_storage.data_disk_size = AAZIntArg(
            options=["data-disk-size"],
            help="Managed Disk size in GB. The maximum supported disk size for Standard and Premium HDD/SSD is 32TB, except for Premium SSD v2, which supports up to 64TB.",
        )
        disk_storage.data_disk_type = AAZStrArg(
            options=["data-disk-type"],
            help="Managed Disk Type.",
            enum={"Premium_SSD_LRS": "Premium_SSD_LRS", "Premium_SSD_ZRS": "Premium_SSD_ZRS", "Premium_SSD_v2_LRS": "Premium_SSD_v2_LRS", "Standard_HDD_LRS": "Standard_HDD_LRS", "Standard_SSD_LRS": "Standard_SSD_LRS", "Standard_SSD_ZRS": "Standard_SSD_ZRS"},
        )

        ranger_plugin_profile = cls._args_schema.ranger_plugin_profile
        ranger_plugin_profile.enabled = AAZBoolArg(
            options=["enabled"],
            help="Enable Ranger for cluster or not.",
        )

        ranger_profile = cls._args_schema.ranger_profile
        ranger_profile.ranger_admin = AAZObjectArg(
            options=["ranger-admin"],
            help="Specification for the Ranger Admin service.",
        )
        ranger_profile.ranger_audit = AAZObjectArg(
            options=["ranger-audit"],
            help="Properties required to describe audit log storage.",
            nullable=True,
        )
        ranger_profile.ranger_usersync = AAZObjectArg(
            options=["ranger-usersync"],
            help="Specification for the Ranger Usersync service",
        )

        ranger_admin = cls._args_schema.ranger_profile.ranger_admin
        ranger_admin.admins = AAZListArg(
            options=["admins"],
            help="List of usernames that should be marked as ranger admins. These usernames should match the user principal name (UPN) of the respective AAD users.",
        )
        ranger_admin.database = AAZObjectArg(
            options=["database"],
        )

        admins = cls._args_schema.ranger_profile.ranger_admin.admins
        admins.Element = AAZStrArg(
            nullable=True,
        )

        database = cls._args_schema.ranger_profile.ranger_admin.database
        database.host = AAZStrArg(
            options=["host"],
            help="The database URL",
        )
        database.name = AAZStrArg(
            options=["name"],
            help="The database name",
        )
        database.password_secret_ref = AAZStrArg(
            options=["password-secret-ref"],
            help="Reference for the database password",
            nullable=True,
        )
        database.username = AAZStrArg(
            options=["username"],
            help="The name of the database user",
            nullable=True,
        )

        ranger_audit = cls._args_schema.ranger_profile.ranger_audit
        ranger_audit.storage_account = AAZStrArg(
            options=["storage-account"],
            help="Azure storage location of the blobs. MSI should have read/write access to this Storage account.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )

        ranger_usersync = cls._args_schema.ranger_profile.ranger_usersync
        ranger_usersync.enabled = AAZBoolArg(
            options=["enabled"],
            help="Denotes whether usersync service should be enabled",
            nullable=True,
        )
        ranger_usersync.groups = AAZListArg(
            options=["groups"],
            help="List of groups that should be synced. These group names should match the object id of the respective AAD groups.",
            nullable=True,
        )
        ranger_usersync.mode = AAZStrArg(
            options=["mode"],
            help="User & groups can be synced automatically or via a static list that's refreshed.",
            nullable=True,
            enum={"automatic": "automatic", "static": "static"},
        )
        ranger_usersync.user_mapping_location = AAZStrArg(
            options=["user-mapping-location"],
            help="Azure storage location of a mapping file that lists user & group associations.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )
        ranger_usersync.users = AAZListArg(
            options=["users"],
            help="List of user names that should be synced. These usernames should match the User principal name of the respective AAD users.",
            nullable=True,
        )

        groups = cls._args_schema.ranger_profile.ranger_usersync.groups
        groups.Element = AAZStrArg(
            nullable=True,
        )

        users = cls._args_schema.ranger_profile.ranger_usersync.users
        users.Element = AAZStrArg(
            nullable=True,
        )

        script_action_profiles = cls._args_schema.script_action_profiles
        script_action_profiles.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.script_action_profiles.Element
        _element.name = AAZStrArg(
            options=["name"],
            help="Script name.",
        )
        _element.parameters = AAZStrArg(
            options=["parameters"],
            help="Additional parameters for the script action. It should be space-separated list of arguments required for script execution.",
            nullable=True,
        )
        _element.services = AAZListArg(
            options=["services"],
            help="List of services to apply the script action.",
        )
        _element.should_persist = AAZBoolArg(
            options=["should-persist"],
            help="Specify if the script should persist on the cluster.",
            nullable=True,
        )
        _element.timeout_in_minutes = AAZIntArg(
            options=["timeout-in-minutes"],
            help="Timeout duration for the script action in minutes.",
            nullable=True,
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="Type of the script action. Supported type is bash scripts.",
        )
        _element.url = AAZStrArg(
            options=["url"],
            help="Url of the script file.",
            fmt=AAZStrArgFormat(
                pattern="^(https)|(http)://.*$",
            ),
        )

        services = cls._args_schema.script_action_profiles.Element.services
        services.Element = AAZStrArg(
            nullable=True,
        )

        service_configs_profiles = cls._args_schema.service_configs_profiles
        service_configs_profiles.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element
        _element.configs = AAZListArg(
            options=["configs"],
            help="List of service configs.",
        )
        _element.service_name = AAZStrArg(
            options=["service-name"],
            help="Name of the service the configurations should apply to.",
        )

        configs = cls._args_schema.service_configs_profiles.Element.configs
        configs.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element.configs.Element
        _element.component = AAZStrArg(
            options=["component"],
            help="Name of the component the config files should apply to.",
        )
        _element.files = AAZListArg(
            options=["files"],
            help="List of Config Files.",
        )

        files = cls._args_schema.service_configs_profiles.Element.configs.Element.files
        files.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element.configs.Element.files.Element
        _element.content = AAZStrArg(
            options=["content"],
            help="Free form content of the entire configuration file.",
            nullable=True,
        )
        _element.encoding = AAZStrArg(
            options=["encoding"],
            help="This property indicates if the content is encoded and is case-insensitive. Please set the value to base64 if the content is base64 encoded. Set it to none or skip it if the content is plain text.",
            nullable=True,
            enum={"Base64": "Base64", "None": "None"},
        )
        _element.file_name = AAZStrArg(
            options=["file-name"],
            help="Configuration file name.",
        )
        _element.path = AAZStrArg(
            options=["path"],
            help="Path of the config file if content is specified.",
            nullable=True,
        )
        _element.values = AAZDictArg(
            options=["values"],
            help="List of key value pairs where key represents a valid service configuration name and value represents the value of the config.",
            nullable=True,
        )

        values = cls._args_schema.service_configs_profiles.Element.configs.Element.files.Element.values
        values.Element = AAZStrArg(
            nullable=True,
        )

        user_plugins_spec = cls._args_schema.user_plugins_spec
        user_plugins_spec.plugins = AAZListArg(
            options=["plugins"],
            help="Spark user plugins.",
            nullable=True,
        )

        plugins = cls._args_schema.user_plugins_spec.plugins
        plugins.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.user_plugins_spec.plugins.Element
        _element.path = AAZStrArg(
            options=["path"],
            help="Fully qualified path to the folder containing the plugins.",
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )

        # define Arg Group "ComputeProfile"

        _args_schema = cls._args_schema
        _args_schema.nodes = AAZListArg(
            options=["--nodes"],
            arg_group="ComputeProfile",
            help="The nodes definitions.",
        )

        nodes = cls._args_schema.nodes
        nodes.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.nodes.Element
        _element.count = AAZIntArg(
            options=["count"],
            help="The number of virtual machines.",
            fmt=AAZIntArgFormat(
                minimum=0,
            ),
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="The node type.",
            fmt=AAZStrArgFormat(
                pattern="^(head|Head|HEAD|worker|Worker|WORKER)$",
            ),
        )
        _element.vm_size = AAZStrArg(
            options=["vm-size"],
            help="The virtual machine SKU.",
            fmt=AAZStrArgFormat(
                pattern="^[a-zA-Z0-9_\-]{0,256}$",
            ),
        )

        # define Arg Group "Coordinator"

        _args_schema = cls._args_schema
        _args_schema.coordinator_high_availability_enabled = AAZBoolArg(
            options=["--enable-coord-ha", "--coordinator-high-availability-enabled"],
            arg_group="Coordinator",
            help="The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.",
            nullable=True,
        )
        _args_schema.coordinator_debug_port = AAZIntArg(
            options=["--coord-debug-port", "--coordinator-debug-port"],
            arg_group="Coordinator",
            help="The flag that if enable debug or not. Default: 8008.",
            nullable=True,
        )
        _args_schema.coordinator_debug_suspend = AAZBoolArg(
            options=["--coord-debug-suspend", "--coordinator-debug-suspend"],
            arg_group="Coordinator",
            help="The flag that if suspend debug or not. Default: false.",
            nullable=True,
        )
        _args_schema.coordinator_debug_enabled = AAZBoolArg(
            options=["--enable-coord-debug", "--coordinator-debug-enabled"],
            arg_group="Coordinator",
            help="The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: false.",
            nullable=True,
        )

        # define Arg Group "FlinkProfile"

        _args_schema = cls._args_schema
        _args_schema.metastore_db_connection_authentication_mode = AAZStrArg(
            options=["--flink-db-auth-mode", "--metastore-db-connection-authentication-mode"],
            arg_group="FlinkProfile",
            help="The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization",
            nullable=True,
            enum={"IdentityAuth": "IdentityAuth", "SqlAuth": "SqlAuth"},
        )
        _args_schema.flink_hive_catalog_db_connection_password_secret = AAZStrArg(
            options=["--flink-hive-db-secret", "--flink-hive-catalog-db-connection-password-secret"],
            arg_group="FlinkProfile",
            help="Secret reference name from secretsProfile.secrets containing password for database connection.",
            nullable=True,
        )
        _args_schema.flink_hive_catalog_db_connection_url = AAZStrArg(
            options=["--flink-hive-db-url", "--flink-hive-catalog-db-connection-url"],
            arg_group="FlinkProfile",
            help="Connection string for hive metastore database.",
        )
        _args_schema.flink_hive_catalog_db_connection_user_name = AAZStrArg(
            options=["--flink-hive-db-user", "--flink-hive-catalog-db-connection-user-name"],
            arg_group="FlinkProfile",
            help="User name for database connection.",
            nullable=True,
        )
        _args_schema.deployment_mode = AAZStrArg(
            options=["--deployment-mode"],
            arg_group="FlinkProfile",
            help="A string property that indicates the deployment mode of Flink cluster. It can have one of the following enum values => Application, Session. Default value is Session",
            nullable=True,
            enum={"Application": "Application", "Session": "Session"},
        )
        _args_schema.history_server_cpu = AAZFloatArg(
            options=["--history-server-cpu"],
            arg_group="FlinkProfile",
            help="History server CPU count.",
        )
        _args_schema.history_server_memory = AAZIntArg(
            options=["--history-server-memory"],
            arg_group="FlinkProfile",
            help="History server memory size.",
        )
        _args_schema.job_manager_cpu = AAZFloatArg(
            options=["--job-manager-cpu"],
            arg_group="FlinkProfile",
            help="Job manager CPU count.",
        )
        _args_schema.job_manager_memory = AAZIntArg(
            options=["--job-manager-memory"],
            arg_group="FlinkProfile",
            help="Job manager memory size.",
        )
        _args_schema.job_spec = AAZObjectArg(
            options=["--job-spec"],
            arg_group="FlinkProfile",
            help="Job specifications for flink clusters in application deployment mode. The specification is immutable even if job properties are changed by calling the RunJob API, please use the ListJob API to get the latest job information.",
            nullable=True,
        )
        _args_schema.num_replicas = AAZIntArg(
            options=["--num-replicas"],
            arg_group="FlinkProfile",
            help="The number of task managers.",
            nullable=True,
        )
        _args_schema.flink_storage_uri = AAZStrArg(
            options=["--flink-storage-uri"],
            arg_group="FlinkProfile",
            help="Storage account uri which is used for savepoint and checkpoint state.",
        )
        _args_schema.flink_storage_key = AAZStrArg(
            options=["--flink-storage-key"],
            arg_group="FlinkProfile",
            help="Storage key is only required for wasb(s) storage.",
            nullable=True,
        )
        _args_schema.task_manager_cpu = AAZFloatArg(
            options=["--task-manager-cpu"],
            arg_group="FlinkProfile",
            help="Task manager CPU count.",
        )
        _args_schema.task_manager_memory = AAZIntArg(
            options=["--task-manager-memory"],
            arg_group="FlinkProfile",
            help="The task manager memory size.",
        )

        job_spec = cls._args_schema.job_spec
        job_spec.args = AAZStrArg(
            options=["args"],
            help="A string property representing additional JVM arguments for the Flink job. It should be space separated value.",
            nullable=True,
        )
        job_spec.entry_class = AAZStrArg(
            options=["entry-class"],
            help="A string property that specifies the entry class for the Flink job. If not specified, the entry point is auto-detected from the flink job jar package.",
            nullable=True,
        )
        job_spec.jar_name = AAZStrArg(
            options=["jar-name"],
            help="A string property that represents the name of the job JAR.",
        )
        job_spec.job_jar_directory = AAZStrArg(
            options=["job-jar-directory"],
            help="A string property that specifies the directory where the job JAR is located.",
        )
        job_spec.save_point_name = AAZStrArg(
            options=["save-point-name"],
            help="A string property that represents the name of the savepoint for the Flink job",
            nullable=True,
        )
        job_spec.upgrade_mode = AAZStrArg(
            options=["upgrade-mode"],
            help="A string property that indicates the upgrade mode to be performed on the Flink job. It can have one of the following enum values => STATELESS_UPDATE, UPDATE, LAST_STATE_UPDATE.",
            enum={"LAST_STATE_UPDATE": "LAST_STATE_UPDATE", "STATELESS_UPDATE": "STATELESS_UPDATE", "UPDATE": "UPDATE"},
        )

        # define Arg Group "HDInsightCluster"

        _args_schema = cls._args_schema
        _args_schema.tags = AAZDictArg(
            options=["--tags"],
            arg_group="HDInsightCluster",
            help="Resource tags.",
            nullable=True,
        )

        tags = cls._args_schema.tags
        tags.Element = AAZStrArg(
            nullable=True,
        )

        # define Arg Group "LogAnalyticsProfile"

        _args_schema = cls._args_schema
        _args_schema.log_analytic_profile_metrics_enabled = AAZBoolArg(
            options=["--enable-la-metrics", "--log-analytic-profile-metrics-enabled"],
            arg_group="LogAnalyticsProfile",
            help="True if metrics are enabled, otherwise false.",
            nullable=True,
        )

        # define Arg Group "ManagedIdentityProfile"

        _args_schema = cls._args_schema
        _args_schema.identity_list = AAZListArg(
            options=["--identity-list"],
            arg_group="ManagedIdentityProfile",
            help="The list of managed identity.",
        )

        identity_list = cls._args_schema.identity_list
        identity_list.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.identity_list.Element
        _element.client_id = AAZStrArg(
            options=["client-id"],
            help="ClientId of the managed identity.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _element.object_id = AAZStrArg(
            options=["object-id"],
            help="ObjectId of the managed identity.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _element.resource_id = AAZResourceIdArg(
            options=["resource-id"],
            help="ResourceId of the managed identity.",
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="The type of managed identity.",
            enum={"cluster": "cluster", "internal": "internal", "user": "user"},
        )

        # define Arg Group "PrometheusProfile"

        _args_schema = cls._args_schema
        _args_schema.enable_prometheu = AAZBoolArg(
            options=["--enable-prometheu"],
            arg_group="PrometheusProfile",
            help="Enable Prometheus for cluster or not.",
        )

        # define Arg Group "SecretsProfile"

        _args_schema = cls._args_schema
        _args_schema.key_vault_id = AAZResourceIdArg(
            options=["--key-vault-id"],
            arg_group="SecretsProfile",
            help="Name of the user Key Vault where all the cluster specific user secrets are stored.",
        )
        _args_schema.secret_reference = AAZListArg(
            options=["--secret-reference"],
            arg_group="SecretsProfile",
            help="Properties of Key Vault secret.",
            nullable=True,
        )

        secret_reference = cls._args_schema.secret_reference
        secret_reference.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.secret_reference.Element
        _element.secret_name = AAZStrArg(
            options=["secret-name"],
            help="Object identifier name of the secret in key vault.",
            fmt=AAZStrArgFormat(
                pattern="^[a-zA-Z][a-zA-Z0-9-]{1,126}$",
            ),
        )
        _element.reference_name = AAZStrArg(
            options=["reference-name"],
            help="Reference name of the secret to be used in service configs.",
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="Type of key vault object: secret, key or certificate.",
            enum={"Certificate": "Certificate", "Key": "Key", "Secret": "Secret"},
        )
        _element.version = AAZStrArg(
            options=["version"],
            help="Version of the secret in key vault.",
            nullable=True,
        )

        # define Arg Group "SparkProfile"

        _args_schema = cls._args_schema
        _args_schema.db_connection_authentication_mode = AAZStrArg(
            options=["--spark-db-auth-mode", "--db-connection-authentication-mode"],
            arg_group="SparkProfile",
            help="The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization",
            nullable=True,
            enum={"IdentityAuth": "IdentityAuth", "SqlAuth": "SqlAuth"},
        )
        _args_schema.spark_hive_catalog_db_name = AAZStrArg(
            options=["--spark-hive-db-name", "--spark-hive-catalog-db-name"],
            arg_group="SparkProfile",
            help="The database name.",
        )
        _args_schema.spark_hive_catalog_db_password_secret = AAZStrArg(
            options=["--spark-hive-db-secret", "--spark-hive-catalog-db-password-secret"],
            arg_group="SparkProfile",
            help="The secret name which contains the database user password.",
            nullable=True,
        )
        _args_schema.spark_hive_catalog_db_server_name = AAZStrArg(
            options=["--spark-hive-db-server", "--spark-hive-catalog-db-server-name"],
            arg_group="SparkProfile",
            help="The database server host.",
        )
        _args_schema.spark_hive_catalog_db_user_name = AAZStrArg(
            options=["--spark-hive-db-user", "--spark-hive-catalog-db-user-name"],
            arg_group="SparkProfile",
            help="The database user name.",
            nullable=True,
        )
        _args_schema.spark_hive_catalog_key_vault_id = AAZStrArg(
            options=["--spark-hive-kv-id", "--spark-hive-catalog-key-vault-id"],
            arg_group="SparkProfile",
            help="The key vault resource id.",
            nullable=True,
        )
        _args_schema.spark_hive_catalog_thrift_url = AAZStrArg(
            options=["--spark-hive-thrift-url", "--spark-hive-catalog-thrift-url"],
            arg_group="SparkProfile",
            help="The thrift url.",
            nullable=True,
        )

        # define Arg Group "SshProfile"

        _args_schema = cls._args_schema
        _args_schema.vm_size = AAZStrArg(
            options=["--vm-size"],
            arg_group="SshProfile",
            help="The virtual machine SKU.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^[a-zA-Z0-9_\-]{0,256}$",
            ),
        )

        # define Arg Group "TrinoClusterWorker"

        _args_schema = cls._args_schema
        _args_schema.enable_worker_debug = AAZBoolArg(
            options=["--enable-worker-debug"],
            arg_group="TrinoClusterWorker",
            help="The flag that if trino cluster enable debug or not. Default: false.",
            nullable=True,
        )
        _args_schema.worker_debug_port = AAZIntArg(
            options=["--worker-debug-port"],
            arg_group="TrinoClusterWorker",
            help="The debug port. Default: 8008.",
            nullable=True,
        )
        _args_schema.worker_debug_suspend = AAZBoolArg(
            options=["--worker-debug-suspend"],
            arg_group="TrinoClusterWorker",
            help="The flag that if trino cluster suspend debug or not. Default: false.",
            nullable=True,
        )

        # define Arg Group "TrinoHiveCatalog"

        _args_schema = cls._args_schema
        _args_schema.trino_hive_catalog = AAZListArg(
            options=["--trino-hive-catalog"],
            arg_group="TrinoHiveCatalog",
            help="hive catalog options.",
            nullable=True,
        )

        trino_hive_catalog = cls._args_schema.trino_hive_catalog
        trino_hive_catalog.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.trino_hive_catalog.Element
        _element.catalog_name = AAZStrArg(
            options=["catalog-name"],
            help="Name of trino catalog which should use specified hive metastore.",
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        _element.metastore_db_connection_authentication_mode = AAZStrArg(
            options=["metastore-db-connection-authentication-mode"],
            help="The authentication mode to connect to your Hive metastore database. More details: https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage?view=azuresql#authentication-and-authorization",
            nullable=True,
            enum={"IdentityAuth": "IdentityAuth", "SqlAuth": "SqlAuth"},
        )
        _element.metastore_db_connection_password_secret = AAZStrArg(
            options=["metastore-db-connection-password-secret"],
            help="Secret reference name from secretsProfile.secrets containing password for database connection.",
            nullable=True,
        )
        _element.metastore_db_connection_url = AAZStrArg(
            options=["metastore-db-connection-url"],
            help="Connection string for hive metastore database.",
        )
        _element.metastore_db_connection_user_name = AAZStrArg(
            options=["metastore-db-connection-user-name"],
            help="User name for database connection.",
            nullable=True,
        )
        _element.metastore_warehouse_dir = AAZStrArg(
            options=["metastore-warehouse-dir"],
            help="Metastore root directory URI, format: abfs[s]://<container>@<account_name>.dfs.core.windows.net/<path>. More details: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction-abfs-uri",
        )

        # define Arg Group "TrinoProfile"

        _args_schema = cls._args_schema
        _args_schema.trino_profile_user_plugins_plugin_spec = AAZObjectArg(
            options=["--trino-plugins-spec", "--trino-profile-user-plugins-plugin-spec"],
            arg_group="TrinoProfile",
            help="Trino user plugins spec",
            nullable=True,
        )
        _args_schema.trino_profile_user_plugins_telemetry_spec = AAZObjectArg(
            options=["--trino-telemetry-spec", "--trino-profile-user-plugins-telemetry-spec"],
            arg_group="TrinoProfile",
            help="Trino user telemetry spec.",
            nullable=True,
        )

        trino_profile_user_plugins_plugin_spec = cls._args_schema.trino_profile_user_plugins_plugin_spec
        trino_profile_user_plugins_plugin_spec.plugins = AAZListArg(
            options=["plugins"],
            help="Trino user plugins.",
            nullable=True,
        )

        plugins = cls._args_schema.trino_profile_user_plugins_plugin_spec.plugins
        plugins.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.trino_profile_user_plugins_plugin_spec.plugins.Element
        _element.enabled = AAZBoolArg(
            options=["enabled"],
            help="Denotes whether the plugin is active or not.",
            nullable=True,
        )
        _element.name = AAZStrArg(
            options=["name"],
            help="This field maps to the sub-directory in trino plugins location, that will contain all the plugins under path.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        _element.path = AAZStrArg(
            options=["path"],
            help="Fully qualified path to the folder containing the plugins.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )

        trino_profile_user_plugins_telemetry_spec = cls._args_schema.trino_profile_user_plugins_telemetry_spec
        trino_profile_user_plugins_telemetry_spec.storage = AAZObjectArg(
            options=["storage"],
            help="Trino user telemetry definition.",
            nullable=True,
        )

        storage = cls._args_schema.trino_profile_user_plugins_telemetry_spec.storage
        storage.hivecatalog_name = AAZStrArg(
            options=["hivecatalog-name"],
            help="Hive Catalog name used to mount external tables on the logs written by trino, if not specified there tables are not created.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        storage.hivecatalog_schema = AAZStrArg(
            options=["hivecatalog-schema"],
            help="Schema of the above catalog to use, to mount query logs as external tables, if not specified tables will be mounted under schema trinologs.",
            nullable=True,
        )
        storage.partition_retention_in_days = AAZIntArg(
            options=["partition-retention-in-days"],
            help="Retention period for query log table partitions, this doesn't have any affect on actual data.",
            nullable=True,
        )
        storage.path = AAZStrArg(
            options=["path"],
            help="Azure storage location of the blobs.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        return cls._args_schema

    def _execute_operations(self):
        self.pre_operations()
        self.ClustersGet(ctx=self.ctx)()
        self.pre_instance_update(self.ctx.vars.instance)
        self.InstanceUpdateByJson(ctx=self.ctx)()
        self.InstanceUpdateByGeneric(ctx=self.ctx)()
        self.post_instance_update(self.ctx.vars.instance)
        yield self.ClustersCreate(ctx=self.ctx)()
        self.post_operations()

    @register_callback
    def pre_operations(self):
        pass

    @register_callback
    def post_operations(self):
        pass

    @register_callback
    def pre_instance_update(self, instance):
        pass

    @register_callback
    def post_instance_update(self, instance):
        pass

    def _output(self, *args, **kwargs):
        result = self.deserialize_output(self.ctx.vars.instance, client_flatten=True)
        return result

    class ClustersGet(AAZHttpOperation):
        CLIENT_TYPE = "MgmtClient"

        def __call__(self, *args, **kwargs):
            request = self.make_request()
            session = self.client.send_request(request=request, stream=False, **kwargs)
            if session.http_response.status_code in [200]:
                return self.on_200(session)

            return self.on_error(session.http_response)

        @property
        def url(self):
            return self.client.format_url(
                "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.HDInsight/clusterpools/{clusterPoolName}/clusters/{clusterName}",
                **self.url_parameters
            )

        @property
        def method(self):
            return "GET"

        @property
        def error_format(self):
            return "MgmtErrorFormat"

        @property
        def url_parameters(self):
            parameters = {
                **self.serialize_url_param(
                    "clusterName", self.ctx.args.cluster_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "clusterPoolName", self.ctx.args.cluster_pool_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "resourceGroupName", self.ctx.args.resource_group,
                    required=True,
                ),
                **self.serialize_url_param(
                    "subscriptionId", self.ctx.subscription_id,
                    required=True,
                ),
            }
            return parameters

        @property
        def query_parameters(self):
            parameters = {
                **self.serialize_query_param(
                    "api-version", "2024-05-01",
                    required=True,
                ),
            }
            return parameters

        @property
        def header_parameters(self):
            parameters = {
                **self.serialize_header_param(
                    "Accept", "application/json",
                ),
            }
            return parameters

        def on_200(self, session):
            data = self.deserialize_http_content(session)
            self.ctx.set_var(
                "instance",
                data,
                schema_builder=self._build_schema_on_200
            )

        _schema_on_200 = None

        @classmethod
        def _build_schema_on_200(cls):
            if cls._schema_on_200 is not None:
                return cls._schema_on_200

            cls._schema_on_200 = AAZObjectType()
            _UpdateHelper._build_schema_cluster_read(cls._schema_on_200)

            return cls._schema_on_200

    class ClustersCreate(AAZHttpOperation):
        CLIENT_TYPE = "MgmtClient"

        def __call__(self, *args, **kwargs):
            request = self.make_request()
            session = self.client.send_request(request=request, stream=False, **kwargs)
            if session.http_response.status_code in [202]:
                return self.client.build_lro_polling(
                    self.ctx.args.no_wait,
                    session,
                    self.on_200_201,
                    self.on_error,
                    lro_options={"final-state-via": "azure-async-operation"},
                    path_format_arguments=self.url_parameters,
                )
            if session.http_response.status_code in [200, 201]:
                return self.client.build_lro_polling(
                    self.ctx.args.no_wait,
                    session,
                    self.on_200_201,
                    self.on_error,
                    lro_options={"final-state-via": "azure-async-operation"},
                    path_format_arguments=self.url_parameters,
                )

            return self.on_error(session.http_response)

        @property
        def url(self):
            return self.client.format_url(
                "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.HDInsight/clusterpools/{clusterPoolName}/clusters/{clusterName}",
                **self.url_parameters
            )

        @property
        def method(self):
            return "PUT"

        @property
        def error_format(self):
            return "MgmtErrorFormat"

        @property
        def url_parameters(self):
            parameters = {
                **self.serialize_url_param(
                    "clusterName", self.ctx.args.cluster_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "clusterPoolName", self.ctx.args.cluster_pool_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "resourceGroupName", self.ctx.args.resource_group,
                    required=True,
                ),
                **self.serialize_url_param(
                    "subscriptionId", self.ctx.subscription_id,
                    required=True,
                ),
            }
            return parameters

        @property
        def query_parameters(self):
            parameters = {
                **self.serialize_query_param(
                    "api-version", "2024-05-01",
                    required=True,
                ),
            }
            return parameters

        @property
        def header_parameters(self):
            parameters = {
                **self.serialize_header_param(
                    "Content-Type", "application/json",
                ),
                **self.serialize_header_param(
                    "Accept", "application/json",
                ),
            }
            return parameters

        @property
        def content(self):
            _content_value, _builder = self.new_content_builder(
                self.ctx.args,
                value=self.ctx.vars.instance,
            )

            return self.serialize_content(_content_value)

        def on_200_201(self, session):
            data = self.deserialize_http_content(session)
            self.ctx.set_var(
                "instance",
                data,
                schema_builder=self._build_schema_on_200_201
            )

        _schema_on_200_201 = None

        @classmethod
        def _build_schema_on_200_201(cls):
            if cls._schema_on_200_201 is not None:
                return cls._schema_on_200_201

            cls._schema_on_200_201 = AAZObjectType()
            _UpdateHelper._build_schema_cluster_read(cls._schema_on_200_201)

            return cls._schema_on_200_201

    class InstanceUpdateByJson(AAZJsonInstanceUpdateOperation):

        def __call__(self, *args, **kwargs):
            self._update_instance(self.ctx.vars.instance)

        def _update_instance(self, instance):
            _instance_value, _builder = self.new_content_builder(
                self.ctx.args,
                value=instance,
                typ=AAZObjectType
            )
            _builder.set_prop("properties", AAZObjectType, typ_kwargs={"flags": {"client_flatten": True}})
            _builder.set_prop("tags", AAZDictType, ".tags")

            properties = _builder.get(".properties")
            if properties is not None:
                properties.set_prop("clusterProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                properties.set_prop("computeProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})

            cluster_profile = _builder.get(".properties.clusterProfile")
            if cluster_profile is not None:
                cluster_profile.set_prop("authorizationProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("autoscaleProfile", AAZObjectType)
                cluster_profile.set_prop("clusterVersion", AAZStrType, ".cluster_version", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("flinkProfile", AAZObjectType)
                cluster_profile.set_prop("identityProfile", AAZObjectType)
                cluster_profile.set_prop("kafkaProfile", AAZObjectType, ".kafka_profile")
                cluster_profile.set_prop("llapProfile", AAZFreeFormDictType, ".llap_profile")
                cluster_profile.set_prop("logAnalyticsProfile", AAZObjectType)
                cluster_profile.set_prop("managedIdentityProfile", AAZObjectType)
                cluster_profile.set_prop("ossVersion", AAZStrType, ".oss_version", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("prometheusProfile", AAZObjectType)
                cluster_profile.set_prop("rangerPluginProfile", AAZObjectType, ".ranger_plugin_profile")
                cluster_profile.set_prop("rangerProfile", AAZObjectType, ".ranger_profile")
                cluster_profile.set_prop("scriptActionProfiles", AAZListType, ".script_action_profiles")
                cluster_profile.set_prop("secretsProfile", AAZObjectType)
                cluster_profile.set_prop("serviceConfigsProfiles", AAZListType, ".service_configs_profiles")
                cluster_profile.set_prop("sparkProfile", AAZObjectType)
                cluster_profile.set_prop("sshProfile", AAZObjectType)
                cluster_profile.set_prop("stubProfile", AAZFreeFormDictType, ".stub_profile")
                cluster_profile.set_prop("trinoProfile", AAZObjectType)

            authorization_profile = _builder.get(".properties.clusterProfile.authorizationProfile")
            if authorization_profile is not None:
                authorization_profile.set_prop("groupIds", AAZListType, ".authorization_group_id")
                authorization_profile.set_prop("userIds", AAZListType, ".authorization_user_id")

            group_ids = _builder.get(".properties.clusterProfile.authorizationProfile.groupIds")
            if group_ids is not None:
                group_ids.set_elements(AAZStrType, ".")

            user_ids = _builder.get(".properties.clusterProfile.authorizationProfile.userIds")
            if user_ids is not None:
                user_ids.set_elements(AAZStrType, ".")

            autoscale_profile = _builder.get(".properties.clusterProfile.autoscaleProfile")
            if autoscale_profile is not None:
                autoscale_profile.set_prop("autoscaleType", AAZStrType, ".autoscale_profile_type")
                autoscale_profile.set_prop("enabled", AAZBoolType, ".enable_autoscale", typ_kwargs={"flags": {"required": True}})
                autoscale_profile.set_prop("gracefulDecommissionTimeout", AAZIntType, ".autoscale_profile_graceful_decommission_timeout")
                autoscale_profile.set_prop("loadBasedConfig", AAZObjectType)
                autoscale_profile.set_prop("scheduleBasedConfig", AAZObjectType)

            load_based_config = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig")
            if load_based_config is not None:
                load_based_config.set_prop("cooldownPeriod", AAZIntType, ".loadbased_config_cooldown_period")
                load_based_config.set_prop("maxNodes", AAZIntType, ".loadbased_config_max_nodes", typ_kwargs={"flags": {"required": True}})
                load_based_config.set_prop("minNodes", AAZIntType, ".loadbased_config_min_nodes", typ_kwargs={"flags": {"required": True}})
                load_based_config.set_prop("pollInterval", AAZIntType, ".loadbased_config_poll_interval")
                load_based_config.set_prop("scalingRules", AAZListType, ".loadbased_config_scaling_rules", typ_kwargs={"flags": {"required": True}})

            scaling_rules = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules")
            if scaling_rules is not None:
                scaling_rules.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules[]")
            if _elements is not None:
                _elements.set_prop("actionType", AAZStrType, ".action_type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("comparisonRule", AAZObjectType, ".comparison_rule", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("evaluationCount", AAZIntType, ".evaluation_count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("scalingMetric", AAZStrType, ".scaling_metric", typ_kwargs={"flags": {"required": True}})

            comparison_rule = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules[].comparisonRule")
            if comparison_rule is not None:
                comparison_rule.set_prop("operator", AAZStrType, ".operator", typ_kwargs={"flags": {"required": True}})
                comparison_rule.set_prop("threshold", AAZFloatType, ".threshold", typ_kwargs={"flags": {"required": True}})

            schedule_based_config = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig")
            if schedule_based_config is not None:
                schedule_based_config.set_prop("defaultCount", AAZIntType, ".schedule_based_config_default_count", typ_kwargs={"flags": {"required": True}})
                schedule_based_config.set_prop("schedules", AAZListType, ".schedule_based_config_schedule", typ_kwargs={"flags": {"required": True}})
                schedule_based_config.set_prop("timeZone", AAZStrType, ".schedule_based_config_time_zone", typ_kwargs={"flags": {"required": True}})

            schedules = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules")
            if schedules is not None:
                schedules.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules[]")
            if _elements is not None:
                _elements.set_prop("count", AAZIntType, ".count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("days", AAZListType, ".days", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("endTime", AAZStrType, ".end_time", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("startTime", AAZStrType, ".start_time", typ_kwargs={"flags": {"required": True}})

            days = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules[].days")
            if days is not None:
                days.set_elements(AAZStrType, ".")

            flink_profile = _builder.get(".properties.clusterProfile.flinkProfile")
            if flink_profile is not None:
                flink_profile.set_prop("catalogOptions", AAZObjectType)
                flink_profile.set_prop("deploymentMode", AAZStrType, ".deployment_mode")
                flink_profile.set_prop("historyServer", AAZObjectType)
                flink_profile.set_prop("jobManager", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                flink_profile.set_prop("jobSpec", AAZObjectType, ".job_spec")
                flink_profile.set_prop("numReplicas", AAZIntType, ".num_replicas")
                flink_profile.set_prop("storage", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                flink_profile.set_prop("taskManager", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})

            catalog_options = _builder.get(".properties.clusterProfile.flinkProfile.catalogOptions")
            if catalog_options is not None:
                catalog_options.set_prop("hive", AAZObjectType)

            hive = _builder.get(".properties.clusterProfile.flinkProfile.catalogOptions.hive")
            if hive is not None:
                hive.set_prop("metastoreDbConnectionAuthenticationMode", AAZStrType, ".metastore_db_connection_authentication_mode")
                hive.set_prop("metastoreDbConnectionPasswordSecret", AAZStrType, ".flink_hive_catalog_db_connection_password_secret")
                hive.set_prop("metastoreDbConnectionURL", AAZStrType, ".flink_hive_catalog_db_connection_url", typ_kwargs={"flags": {"required": True}})
                hive.set_prop("metastoreDbConnectionUserName", AAZStrType, ".flink_hive_catalog_db_connection_user_name")

            history_server = _builder.get(".properties.clusterProfile.flinkProfile.historyServer")
            if history_server is not None:
                history_server.set_prop("cpu", AAZFloatType, ".history_server_cpu", typ_kwargs={"flags": {"required": True}})
                history_server.set_prop("memory", AAZIntType, ".history_server_memory", typ_kwargs={"flags": {"required": True}})

            job_manager = _builder.get(".properties.clusterProfile.flinkProfile.jobManager")
            if job_manager is not None:
                job_manager.set_prop("cpu", AAZFloatType, ".job_manager_cpu", typ_kwargs={"flags": {"required": True}})
                job_manager.set_prop("memory", AAZIntType, ".job_manager_memory", typ_kwargs={"flags": {"required": True}})

            job_spec = _builder.get(".properties.clusterProfile.flinkProfile.jobSpec")
            if job_spec is not None:
                job_spec.set_prop("args", AAZStrType, ".args")
                job_spec.set_prop("entryClass", AAZStrType, ".entry_class")
                job_spec.set_prop("jarName", AAZStrType, ".jar_name", typ_kwargs={"flags": {"required": True}})
                job_spec.set_prop("jobJarDirectory", AAZStrType, ".job_jar_directory", typ_kwargs={"flags": {"required": True}})
                job_spec.set_prop("savePointName", AAZStrType, ".save_point_name")
                job_spec.set_prop("upgradeMode", AAZStrType, ".upgrade_mode", typ_kwargs={"flags": {"required": True}})

            storage = _builder.get(".properties.clusterProfile.flinkProfile.storage")
            if storage is not None:
                storage.set_prop("storageUri", AAZStrType, ".flink_storage_uri", typ_kwargs={"flags": {"required": True}})
                storage.set_prop("storagekey", AAZStrType, ".flink_storage_key", typ_kwargs={"flags": {"secret": True}})

            task_manager = _builder.get(".properties.clusterProfile.flinkProfile.taskManager")
            if task_manager is not None:
                task_manager.set_prop("cpu", AAZFloatType, ".task_manager_cpu", typ_kwargs={"flags": {"required": True}})
                task_manager.set_prop("memory", AAZIntType, ".task_manager_memory", typ_kwargs={"flags": {"required": True}})

            identity_profile = _builder.get(".properties.clusterProfile.identityProfile")
            if identity_profile is not None:
                identity_profile.set_prop("msiClientId", AAZStrType, ".assigned_identity_client_id", typ_kwargs={"flags": {"required": True}})
                identity_profile.set_prop("msiObjectId", AAZStrType, ".assigned_identity_object_id", typ_kwargs={"flags": {"required": True}})
                identity_profile.set_prop("msiResourceId", AAZStrType, ".assigned_identity_id", typ_kwargs={"flags": {"required": True}})

            kafka_profile = _builder.get(".properties.clusterProfile.kafkaProfile")
            if kafka_profile is not None:
                kafka_profile.set_prop("diskStorage", AAZObjectType, ".disk_storage", typ_kwargs={"flags": {"required": True}})
                kafka_profile.set_prop("enableKRaft", AAZBoolType, ".enable_k_raft")
                kafka_profile.set_prop("enablePublicEndpoints", AAZBoolType, ".enable_public_endpoints")
                kafka_profile.set_prop("remoteStorageUri", AAZStrType, ".remote_storage_uri")

            disk_storage = _builder.get(".properties.clusterProfile.kafkaProfile.diskStorage")
            if disk_storage is not None:
                disk_storage.set_prop("dataDiskSize", AAZIntType, ".data_disk_size", typ_kwargs={"flags": {"required": True}})
                disk_storage.set_prop("dataDiskType", AAZStrType, ".data_disk_type", typ_kwargs={"flags": {"required": True}})

            llap_profile = _builder.get(".properties.clusterProfile.llapProfile")
            if llap_profile is not None:
                llap_profile.set_anytype_elements(".")

            log_analytics_profile = _builder.get(".properties.clusterProfile.logAnalyticsProfile")
            if log_analytics_profile is not None:
                log_analytics_profile.set_prop("applicationLogs", AAZObjectType)
                log_analytics_profile.set_prop("enabled", AAZBoolType, ".enable_log_analytics", typ_kwargs={"flags": {"required": True}})
                log_analytics_profile.set_prop("metricsEnabled", AAZBoolType, ".log_analytic_profile_metrics_enabled")

            application_logs = _builder.get(".properties.clusterProfile.logAnalyticsProfile.applicationLogs")
            if application_logs is not None:
                application_logs.set_prop("stdErrorEnabled", AAZBoolType, ".application_log_std_error_enabled")
                application_logs.set_prop("stdOutEnabled", AAZBoolType, ".application_log_std_out_enabled")

            managed_identity_profile = _builder.get(".properties.clusterProfile.managedIdentityProfile")
            if managed_identity_profile is not None:
                managed_identity_profile.set_prop("identityList", AAZListType, ".identity_list", typ_kwargs={"flags": {"required": True}})

            identity_list = _builder.get(".properties.clusterProfile.managedIdentityProfile.identityList")
            if identity_list is not None:
                identity_list.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.managedIdentityProfile.identityList[]")
            if _elements is not None:
                _elements.set_prop("clientId", AAZStrType, ".client_id", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("objectId", AAZStrType, ".object_id", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("resourceId", AAZStrType, ".resource_id", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})

            prometheus_profile = _builder.get(".properties.clusterProfile.prometheusProfile")
            if prometheus_profile is not None:
                prometheus_profile.set_prop("enabled", AAZBoolType, ".enable_prometheu", typ_kwargs={"flags": {"required": True}})

            ranger_plugin_profile = _builder.get(".properties.clusterProfile.rangerPluginProfile")
            if ranger_plugin_profile is not None:
                ranger_plugin_profile.set_prop("enabled", AAZBoolType, ".enabled", typ_kwargs={"flags": {"required": True}})

            ranger_profile = _builder.get(".properties.clusterProfile.rangerProfile")
            if ranger_profile is not None:
                ranger_profile.set_prop("rangerAdmin", AAZObjectType, ".ranger_admin", typ_kwargs={"flags": {"required": True}})
                ranger_profile.set_prop("rangerAudit", AAZObjectType, ".ranger_audit")
                ranger_profile.set_prop("rangerUsersync", AAZObjectType, ".ranger_usersync", typ_kwargs={"flags": {"required": True}})

            ranger_admin = _builder.get(".properties.clusterProfile.rangerProfile.rangerAdmin")
            if ranger_admin is not None:
                ranger_admin.set_prop("admins", AAZListType, ".admins", typ_kwargs={"flags": {"required": True}})
                ranger_admin.set_prop("database", AAZObjectType, ".database", typ_kwargs={"flags": {"required": True}})

            admins = _builder.get(".properties.clusterProfile.rangerProfile.rangerAdmin.admins")
            if admins is not None:
                admins.set_elements(AAZStrType, ".")

            database = _builder.get(".properties.clusterProfile.rangerProfile.rangerAdmin.database")
            if database is not None:
                database.set_prop("host", AAZStrType, ".host", typ_kwargs={"flags": {"required": True}})
                database.set_prop("name", AAZStrType, ".name", typ_kwargs={"flags": {"required": True}})
                database.set_prop("passwordSecretRef", AAZStrType, ".password_secret_ref")
                database.set_prop("username", AAZStrType, ".username")

            ranger_audit = _builder.get(".properties.clusterProfile.rangerProfile.rangerAudit")
            if ranger_audit is not None:
                ranger_audit.set_prop("storageAccount", AAZStrType, ".storage_account")

            ranger_usersync = _builder.get(".properties.clusterProfile.rangerProfile.rangerUsersync")
            if ranger_usersync is not None:
                ranger_usersync.set_prop("enabled", AAZBoolType, ".enabled")
                ranger_usersync.set_prop("groups", AAZListType, ".groups")
                ranger_usersync.set_prop("mode", AAZStrType, ".mode")
                ranger_usersync.set_prop("userMappingLocation", AAZStrType, ".user_mapping_location")
                ranger_usersync.set_prop("users", AAZListType, ".users")

            groups = _builder.get(".properties.clusterProfile.rangerProfile.rangerUsersync.groups")
            if groups is not None:
                groups.set_elements(AAZStrType, ".")

            users = _builder.get(".properties.clusterProfile.rangerProfile.rangerUsersync.users")
            if users is not None:
                users.set_elements(AAZStrType, ".")

            script_action_profiles = _builder.get(".properties.clusterProfile.scriptActionProfiles")
            if script_action_profiles is not None:
                script_action_profiles.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.scriptActionProfiles[]")
            if _elements is not None:
                _elements.set_prop("name", AAZStrType, ".name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("parameters", AAZStrType, ".parameters")
                _elements.set_prop("services", AAZListType, ".services", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("shouldPersist", AAZBoolType, ".should_persist")
                _elements.set_prop("timeoutInMinutes", AAZIntType, ".timeout_in_minutes")
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("url", AAZStrType, ".url", typ_kwargs={"flags": {"required": True}})

            services = _builder.get(".properties.clusterProfile.scriptActionProfiles[].services")
            if services is not None:
                services.set_elements(AAZStrType, ".")

            secrets_profile = _builder.get(".properties.clusterProfile.secretsProfile")
            if secrets_profile is not None:
                secrets_profile.set_prop("keyVaultResourceId", AAZStrType, ".key_vault_id", typ_kwargs={"flags": {"required": True}})
                secrets_profile.set_prop("secrets", AAZListType, ".secret_reference")

            secrets = _builder.get(".properties.clusterProfile.secretsProfile.secrets")
            if secrets is not None:
                secrets.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.secretsProfile.secrets[]")
            if _elements is not None:
                _elements.set_prop("keyVaultObjectName", AAZStrType, ".secret_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("referenceName", AAZStrType, ".reference_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("version", AAZStrType, ".version")

            service_configs_profiles = _builder.get(".properties.clusterProfile.serviceConfigsProfiles")
            if service_configs_profiles is not None:
                service_configs_profiles.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[]")
            if _elements is not None:
                _elements.set_prop("configs", AAZListType, ".configs", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("serviceName", AAZStrType, ".service_name", typ_kwargs={"flags": {"required": True}})

            configs = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs")
            if configs is not None:
                configs.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[]")
            if _elements is not None:
                _elements.set_prop("component", AAZStrType, ".component", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("files", AAZListType, ".files", typ_kwargs={"flags": {"required": True}})

            files = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files")
            if files is not None:
                files.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files[]")
            if _elements is not None:
                _elements.set_prop("content", AAZStrType, ".content")
                _elements.set_prop("encoding", AAZStrType, ".encoding")
                _elements.set_prop("fileName", AAZStrType, ".file_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("path", AAZStrType, ".path")
                _elements.set_prop("values", AAZDictType, ".values")

            values = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files[].values")
            if values is not None:
                values.set_elements(AAZStrType, ".")

            spark_profile = _builder.get(".properties.clusterProfile.sparkProfile")
            if spark_profile is not None:
                spark_profile.set_prop("defaultStorageUrl", AAZStrType, ".spark_storage_url")
                spark_profile.set_prop("metastoreSpec", AAZObjectType)
                spark_profile.set_prop("userPluginsSpec", AAZObjectType, ".user_plugins_spec")

            metastore_spec = _builder.get(".properties.clusterProfile.sparkProfile.metastoreSpec")
            if metastore_spec is not None:
                metastore_spec.set_prop("dbConnectionAuthenticationMode", AAZStrType, ".db_connection_authentication_mode")
                metastore_spec.set_prop("dbName", AAZStrType, ".spark_hive_catalog_db_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("dbPasswordSecretName", AAZStrType, ".spark_hive_catalog_db_password_secret")
                metastore_spec.set_prop("dbServerHost", AAZStrType, ".spark_hive_catalog_db_server_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("dbUserName", AAZStrType, ".spark_hive_catalog_db_user_name")
                metastore_spec.set_prop("keyVaultId", AAZStrType, ".spark_hive_catalog_key_vault_id")
                metastore_spec.set_prop("thriftUrl", AAZStrType, ".spark_hive_catalog_thrift_url")

            user_plugins_spec = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec")
            if user_plugins_spec is not None:
                user_plugins_spec.set_prop("plugins", AAZListType, ".plugins")

            plugins = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec.plugins")
            if plugins is not None:
                plugins.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec.plugins[]")
            if _elements is not None:
                _elements.set_prop("path", AAZStrType, ".path", typ_kwargs={"flags": {"required": True}})

            ssh_profile = _builder.get(".properties.clusterProfile.sshProfile")
            if ssh_profile is not None:
                ssh_profile.set_prop("count", AAZIntType, ".ssh_profile_count", typ_kwargs={"flags": {"required": True}})
                ssh_profile.set_prop("vmSize", AAZStrType, ".vm_size")

            stub_profile = _builder.get(".properties.clusterProfile.stubProfile")
            if stub_profile is not None:
                stub_profile.set_anytype_elements(".")

            trino_profile = _builder.get(".properties.clusterProfile.trinoProfile")
            if trino_profile is not None:
                trino_profile.set_prop("catalogOptions", AAZObjectType)
                trino_profile.set_prop("coordinator", AAZObjectType)
                trino_profile.set_prop("userPluginsSpec", AAZObjectType, ".trino_profile_user_plugins_plugin_spec")
                trino_profile.set_prop("userTelemetrySpec", AAZObjectType, ".trino_profile_user_plugins_telemetry_spec")
                trino_profile.set_prop("worker", AAZObjectType)

            catalog_options = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions")
            if catalog_options is not None:
                catalog_options.set_prop("hive", AAZListType, ".trino_hive_catalog")

            hive = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions.hive")
            if hive is not None:
                hive.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions.hive[]")
            if _elements is not None:
                _elements.set_prop("catalogName", AAZStrType, ".catalog_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreDbConnectionAuthenticationMode", AAZStrType, ".metastore_db_connection_authentication_mode")
                _elements.set_prop("metastoreDbConnectionPasswordSecret", AAZStrType, ".metastore_db_connection_password_secret")
                _elements.set_prop("metastoreDbConnectionURL", AAZStrType, ".metastore_db_connection_url", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreDbConnectionUserName", AAZStrType, ".metastore_db_connection_user_name")
                _elements.set_prop("metastoreWarehouseDir", AAZStrType, ".metastore_warehouse_dir", typ_kwargs={"flags": {"required": True}})

            coordinator = _builder.get(".properties.clusterProfile.trinoProfile.coordinator")
            if coordinator is not None:
                coordinator.set_prop("debug", AAZObjectType, typ_kwargs={"flags": {"client_flatten": True}})
                coordinator.set_prop("highAvailabilityEnabled", AAZBoolType, ".coordinator_debug_enabled")

            debug = _builder.get(".properties.clusterProfile.trinoProfile.coordinator.debug")
            if debug is not None:
                debug.set_prop("enable", AAZBoolType, ".coordinator_high_availability_enabled")
                debug.set_prop("port", AAZIntType, ".coordinator_debug_port")
                debug.set_prop("suspend", AAZBoolType, ".coordinator_debug_suspend")

            user_plugins_spec = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec")
            if user_plugins_spec is not None:
                user_plugins_spec.set_prop("plugins", AAZListType, ".plugins")

            plugins = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec.plugins")
            if plugins is not None:
                plugins.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec.plugins[]")
            if _elements is not None:
                _elements.set_prop("enabled", AAZBoolType, ".enabled")
                _elements.set_prop("name", AAZStrType, ".name")
                _elements.set_prop("path", AAZStrType, ".path")

            user_telemetry_spec = _builder.get(".properties.clusterProfile.trinoProfile.userTelemetrySpec")
            if user_telemetry_spec is not None:
                user_telemetry_spec.set_prop("storage", AAZObjectType, ".storage")

            storage = _builder.get(".properties.clusterProfile.trinoProfile.userTelemetrySpec.storage")
            if storage is not None:
                storage.set_prop("hivecatalogName", AAZStrType, ".hivecatalog_name")
                storage.set_prop("hivecatalogSchema", AAZStrType, ".hivecatalog_schema")
                storage.set_prop("partitionRetentionInDays", AAZIntType, ".partition_retention_in_days")
                storage.set_prop("path", AAZStrType, ".path")

            worker = _builder.get(".properties.clusterProfile.trinoProfile.worker")
            if worker is not None:
                worker.set_prop("debug", AAZObjectType, typ_kwargs={"flags": {"client_flatten": True}})

            debug = _builder.get(".properties.clusterProfile.trinoProfile.worker.debug")
            if debug is not None:
                debug.set_prop("enable", AAZBoolType, ".enable_worker_debug")
                debug.set_prop("port", AAZIntType, ".worker_debug_port")
                debug.set_prop("suspend", AAZBoolType, ".worker_debug_suspend")

            compute_profile = _builder.get(".properties.computeProfile")
            if compute_profile is not None:
                compute_profile.set_prop("nodes", AAZListType, ".nodes", typ_kwargs={"flags": {"required": True}})

            nodes = _builder.get(".properties.computeProfile.nodes")
            if nodes is not None:
                nodes.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.computeProfile.nodes[]")
            if _elements is not None:
                _elements.set_prop("count", AAZIntType, ".count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("vmSize", AAZStrType, ".vm_size", typ_kwargs={"flags": {"required": True}})

            tags = _builder.get(".tags")
            if tags is not None:
                tags.set_elements(AAZStrType, ".")

            return _instance_value

    class InstanceUpdateByGeneric(AAZGenericInstanceUpdateOperation):

        def __call__(self, *args, **kwargs):
            self._update_instance_by_generic(
                self.ctx.vars.instance,
                self.ctx.generic_update_args
            )


class _UpdateHelper:
    """Helper class for Update"""

    _schema_cluster_read = None

    @classmethod
    def _build_schema_cluster_read(cls, _schema):
        if cls._schema_cluster_read is not None:
            _schema.id = cls._schema_cluster_read.id
            _schema.location = cls._schema_cluster_read.location
            _schema.name = cls._schema_cluster_read.name
            _schema.properties = cls._schema_cluster_read.properties
            _schema.system_data = cls._schema_cluster_read.system_data
            _schema.tags = cls._schema_cluster_read.tags
            _schema.type = cls._schema_cluster_read.type
            return

        cls._schema_cluster_read = _schema_cluster_read = AAZObjectType()

        cluster_read = _schema_cluster_read
        cluster_read.id = AAZStrType(
            flags={"read_only": True},
        )
        cluster_read.location = AAZStrType(
            flags={"required": True},
        )
        cluster_read.name = AAZStrType(
            flags={"read_only": True},
        )
        cluster_read.properties = AAZObjectType(
            flags={"client_flatten": True},
        )
        cluster_read.system_data = AAZObjectType(
            serialized_name="systemData",
            flags={"read_only": True},
        )
        cluster_read.tags = AAZDictType()
        cluster_read.type = AAZStrType(
            flags={"read_only": True},
        )

        properties = _schema_cluster_read.properties
        properties.cluster_profile = AAZObjectType(
            serialized_name="clusterProfile",
            flags={"required": True},
        )
        properties.cluster_type = AAZStrType(
            serialized_name="clusterType",
            flags={"required": True},
        )
        properties.compute_profile = AAZObjectType(
            serialized_name="computeProfile",
            flags={"required": True},
        )
        properties.deployment_id = AAZStrType(
            serialized_name="deploymentId",
            flags={"read_only": True},
        )
        properties.provisioning_state = AAZStrType(
            serialized_name="provisioningState",
            flags={"read_only": True},
        )
        properties.status = AAZStrType(
            flags={"read_only": True},
        )

        cluster_profile = _schema_cluster_read.properties.cluster_profile
        cluster_profile.authorization_profile = AAZObjectType(
            serialized_name="authorizationProfile",
            flags={"required": True},
        )
        cluster_profile.autoscale_profile = AAZObjectType(
            serialized_name="autoscaleProfile",
        )
        cluster_profile.cluster_access_profile = AAZObjectType(
            serialized_name="clusterAccessProfile",
        )
        cluster_profile.cluster_version = AAZStrType(
            serialized_name="clusterVersion",
            flags={"required": True},
        )
        cluster_profile.components = AAZListType(
            flags={"read_only": True},
        )
        cluster_profile.connectivity_profile = AAZObjectType(
            serialized_name="connectivityProfile",
            flags={"read_only": True},
        )
        cluster_profile.flink_profile = AAZObjectType(
            serialized_name="flinkProfile",
        )
        cluster_profile.identity_profile = AAZObjectType(
            serialized_name="identityProfile",
        )
        cluster_profile.kafka_profile = AAZObjectType(
            serialized_name="kafkaProfile",
        )
        cluster_profile.llap_profile = AAZFreeFormDictType(
            serialized_name="llapProfile",
        )
        cluster_profile.log_analytics_profile = AAZObjectType(
            serialized_name="logAnalyticsProfile",
        )
        cluster_profile.managed_identity_profile = AAZObjectType(
            serialized_name="managedIdentityProfile",
        )
        cluster_profile.oss_version = AAZStrType(
            serialized_name="ossVersion",
            flags={"required": True},
        )
        cluster_profile.prometheus_profile = AAZObjectType(
            serialized_name="prometheusProfile",
        )
        cluster_profile.ranger_plugin_profile = AAZObjectType(
            serialized_name="rangerPluginProfile",
        )
        cluster_profile.ranger_profile = AAZObjectType(
            serialized_name="rangerProfile",
        )
        cluster_profile.script_action_profiles = AAZListType(
            serialized_name="scriptActionProfiles",
        )
        cluster_profile.secrets_profile = AAZObjectType(
            serialized_name="secretsProfile",
        )
        cluster_profile.service_configs_profiles = AAZListType(
            serialized_name="serviceConfigsProfiles",
        )
        cluster_profile.spark_profile = AAZObjectType(
            serialized_name="sparkProfile",
        )
        cluster_profile.ssh_profile = AAZObjectType(
            serialized_name="sshProfile",
        )
        cluster_profile.stub_profile = AAZFreeFormDictType(
            serialized_name="stubProfile",
        )
        cluster_profile.trino_profile = AAZObjectType(
            serialized_name="trinoProfile",
        )

        authorization_profile = _schema_cluster_read.properties.cluster_profile.authorization_profile
        authorization_profile.group_ids = AAZListType(
            serialized_name="groupIds",
        )
        authorization_profile.user_ids = AAZListType(
            serialized_name="userIds",
        )

        group_ids = _schema_cluster_read.properties.cluster_profile.authorization_profile.group_ids
        group_ids.Element = AAZStrType()

        user_ids = _schema_cluster_read.properties.cluster_profile.authorization_profile.user_ids
        user_ids.Element = AAZStrType()

        autoscale_profile = _schema_cluster_read.properties.cluster_profile.autoscale_profile
        autoscale_profile.autoscale_type = AAZStrType(
            serialized_name="autoscaleType",
        )
        autoscale_profile.enabled = AAZBoolType(
            flags={"required": True},
        )
        autoscale_profile.graceful_decommission_timeout = AAZIntType(
            serialized_name="gracefulDecommissionTimeout",
        )
        autoscale_profile.load_based_config = AAZObjectType(
            serialized_name="loadBasedConfig",
        )
        autoscale_profile.schedule_based_config = AAZObjectType(
            serialized_name="scheduleBasedConfig",
        )

        load_based_config = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config
        load_based_config.cooldown_period = AAZIntType(
            serialized_name="cooldownPeriod",
        )
        load_based_config.max_nodes = AAZIntType(
            serialized_name="maxNodes",
            flags={"required": True},
        )
        load_based_config.min_nodes = AAZIntType(
            serialized_name="minNodes",
            flags={"required": True},
        )
        load_based_config.poll_interval = AAZIntType(
            serialized_name="pollInterval",
        )
        load_based_config.scaling_rules = AAZListType(
            serialized_name="scalingRules",
            flags={"required": True},
        )

        scaling_rules = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules
        scaling_rules.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules.Element
        _element.action_type = AAZStrType(
            serialized_name="actionType",
            flags={"required": True},
        )
        _element.comparison_rule = AAZObjectType(
            serialized_name="comparisonRule",
            flags={"required": True},
        )
        _element.evaluation_count = AAZIntType(
            serialized_name="evaluationCount",
            flags={"required": True},
        )
        _element.scaling_metric = AAZStrType(
            serialized_name="scalingMetric",
            flags={"required": True},
        )

        comparison_rule = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules.Element.comparison_rule
        comparison_rule.operator = AAZStrType(
            flags={"required": True},
        )
        comparison_rule.threshold = AAZFloatType(
            flags={"required": True},
        )

        schedule_based_config = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config
        schedule_based_config.default_count = AAZIntType(
            serialized_name="defaultCount",
            flags={"required": True},
        )
        schedule_based_config.schedules = AAZListType(
            flags={"required": True},
        )
        schedule_based_config.time_zone = AAZStrType(
            serialized_name="timeZone",
            flags={"required": True},
        )

        schedules = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules
        schedules.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules.Element
        _element.count = AAZIntType(
            flags={"required": True},
        )
        _element.days = AAZListType(
            flags={"required": True},
        )
        _element.end_time = AAZStrType(
            serialized_name="endTime",
            flags={"required": True},
        )
        _element.start_time = AAZStrType(
            serialized_name="startTime",
            flags={"required": True},
        )

        days = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules.Element.days
        days.Element = AAZStrType()

        cluster_access_profile = _schema_cluster_read.properties.cluster_profile.cluster_access_profile
        cluster_access_profile.enable_internal_ingress = AAZBoolType(
            serialized_name="enableInternalIngress",
            flags={"required": True},
        )
        cluster_access_profile.private_link_service_id = AAZStrType(
            serialized_name="privateLinkServiceId",
            flags={"read_only": True},
        )

        components = _schema_cluster_read.properties.cluster_profile.components
        components.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.components.Element
        _element.name = AAZStrType()
        _element.version = AAZStrType()

        connectivity_profile = _schema_cluster_read.properties.cluster_profile.connectivity_profile
        connectivity_profile.ssh = AAZListType()
        connectivity_profile.web = AAZObjectType(
            flags={"required": True},
        )

        ssh = _schema_cluster_read.properties.cluster_profile.connectivity_profile.ssh
        ssh.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.connectivity_profile.ssh.Element
        _element.endpoint = AAZStrType(
            flags={"required": True},
        )
        _element.private_ssh_endpoint = AAZStrType(
            serialized_name="privateSshEndpoint",
        )

        web = _schema_cluster_read.properties.cluster_profile.connectivity_profile.web
        web.fqdn = AAZStrType(
            flags={"required": True},
        )
        web.private_fqdn = AAZStrType(
            serialized_name="privateFqdn",
        )

        flink_profile = _schema_cluster_read.properties.cluster_profile.flink_profile
        flink_profile.catalog_options = AAZObjectType(
            serialized_name="catalogOptions",
        )
        flink_profile.deployment_mode = AAZStrType(
            serialized_name="deploymentMode",
        )
        flink_profile.history_server = AAZObjectType(
            serialized_name="historyServer",
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.history_server)
        flink_profile.job_manager = AAZObjectType(
            serialized_name="jobManager",
            flags={"required": True},
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.job_manager)
        flink_profile.job_spec = AAZObjectType(
            serialized_name="jobSpec",
        )
        flink_profile.num_replicas = AAZIntType(
            serialized_name="numReplicas",
        )
        flink_profile.storage = AAZObjectType(
            flags={"required": True},
        )
        flink_profile.task_manager = AAZObjectType(
            serialized_name="taskManager",
            flags={"required": True},
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.task_manager)

        catalog_options = _schema_cluster_read.properties.cluster_profile.flink_profile.catalog_options
        catalog_options.hive = AAZObjectType()

        hive = _schema_cluster_read.properties.cluster_profile.flink_profile.catalog_options.hive
        hive.metastore_db_connection_authentication_mode = AAZStrType(
            serialized_name="metastoreDbConnectionAuthenticationMode",
        )
        hive.metastore_db_connection_password_secret = AAZStrType(
            serialized_name="metastoreDbConnectionPasswordSecret",
        )
        hive.metastore_db_connection_url = AAZStrType(
            serialized_name="metastoreDbConnectionURL",
            flags={"required": True},
        )
        hive.metastore_db_connection_user_name = AAZStrType(
            serialized_name="metastoreDbConnectionUserName",
        )

        job_spec = _schema_cluster_read.properties.cluster_profile.flink_profile.job_spec
        job_spec.args = AAZStrType()
        job_spec.entry_class = AAZStrType(
            serialized_name="entryClass",
        )
        job_spec.jar_name = AAZStrType(
            serialized_name="jarName",
            flags={"required": True},
        )
        job_spec.job_jar_directory = AAZStrType(
            serialized_name="jobJarDirectory",
            flags={"required": True},
        )
        job_spec.save_point_name = AAZStrType(
            serialized_name="savePointName",
        )
        job_spec.upgrade_mode = AAZStrType(
            serialized_name="upgradeMode",
            flags={"required": True},
        )

        storage = _schema_cluster_read.properties.cluster_profile.flink_profile.storage
        storage.storage_uri = AAZStrType(
            serialized_name="storageUri",
            flags={"required": True},
        )
        storage.storagekey = AAZStrType(
            flags={"secret": True},
        )

        identity_profile = _schema_cluster_read.properties.cluster_profile.identity_profile
        identity_profile.msi_client_id = AAZStrType(
            serialized_name="msiClientId",
            flags={"required": True},
        )
        identity_profile.msi_object_id = AAZStrType(
            serialized_name="msiObjectId",
            flags={"required": True},
        )
        identity_profile.msi_resource_id = AAZStrType(
            serialized_name="msiResourceId",
            flags={"required": True},
        )

        kafka_profile = _schema_cluster_read.properties.cluster_profile.kafka_profile
        kafka_profile.connectivity_endpoints = AAZObjectType(
            serialized_name="connectivityEndpoints",
        )
        kafka_profile.disk_storage = AAZObjectType(
            serialized_name="diskStorage",
            flags={"required": True},
        )
        kafka_profile.enable_k_raft = AAZBoolType(
            serialized_name="enableKRaft",
        )
        kafka_profile.enable_public_endpoints = AAZBoolType(
            serialized_name="enablePublicEndpoints",
        )
        kafka_profile.remote_storage_uri = AAZStrType(
            serialized_name="remoteStorageUri",
        )

        connectivity_endpoints = _schema_cluster_read.properties.cluster_profile.kafka_profile.connectivity_endpoints
        connectivity_endpoints.bootstrap_server_endpoint = AAZStrType(
            serialized_name="bootstrapServerEndpoint",
        )
        connectivity_endpoints.broker_endpoints = AAZListType(
            serialized_name="brokerEndpoints",
        )

        broker_endpoints = _schema_cluster_read.properties.cluster_profile.kafka_profile.connectivity_endpoints.broker_endpoints
        broker_endpoints.Element = AAZStrType()

        disk_storage = _schema_cluster_read.properties.cluster_profile.kafka_profile.disk_storage
        disk_storage.data_disk_size = AAZIntType(
            serialized_name="dataDiskSize",
            flags={"required": True},
        )
        disk_storage.data_disk_type = AAZStrType(
            serialized_name="dataDiskType",
            flags={"required": True},
        )

        log_analytics_profile = _schema_cluster_read.properties.cluster_profile.log_analytics_profile
        log_analytics_profile.application_logs = AAZObjectType(
            serialized_name="applicationLogs",
        )
        log_analytics_profile.enabled = AAZBoolType(
            flags={"required": True},
        )
        log_analytics_profile.metrics_enabled = AAZBoolType(
            serialized_name="metricsEnabled",
        )

        application_logs = _schema_cluster_read.properties.cluster_profile.log_analytics_profile.application_logs
        application_logs.std_error_enabled = AAZBoolType(
            serialized_name="stdErrorEnabled",
        )
        application_logs.std_out_enabled = AAZBoolType(
            serialized_name="stdOutEnabled",
        )

        managed_identity_profile = _schema_cluster_read.properties.cluster_profile.managed_identity_profile
        managed_identity_profile.identity_list = AAZListType(
            serialized_name="identityList",
            flags={"required": True},
        )

        identity_list = _schema_cluster_read.properties.cluster_profile.managed_identity_profile.identity_list
        identity_list.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.managed_identity_profile.identity_list.Element
        _element.client_id = AAZStrType(
            serialized_name="clientId",
            flags={"required": True},
        )
        _element.object_id = AAZStrType(
            serialized_name="objectId",
            flags={"required": True},
        )
        _element.resource_id = AAZStrType(
            serialized_name="resourceId",
            flags={"required": True},
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )

        prometheus_profile = _schema_cluster_read.properties.cluster_profile.prometheus_profile
        prometheus_profile.enabled = AAZBoolType(
            flags={"required": True},
        )

        ranger_plugin_profile = _schema_cluster_read.properties.cluster_profile.ranger_plugin_profile
        ranger_plugin_profile.enabled = AAZBoolType(
            flags={"required": True},
        )

        ranger_profile = _schema_cluster_read.properties.cluster_profile.ranger_profile
        ranger_profile.ranger_admin = AAZObjectType(
            serialized_name="rangerAdmin",
            flags={"required": True},
        )
        ranger_profile.ranger_audit = AAZObjectType(
            serialized_name="rangerAudit",
        )
        ranger_profile.ranger_usersync = AAZObjectType(
            serialized_name="rangerUsersync",
            flags={"required": True},
        )

        ranger_admin = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_admin
        ranger_admin.admins = AAZListType(
            flags={"required": True},
        )
        ranger_admin.database = AAZObjectType(
            flags={"required": True},
        )

        admins = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_admin.admins
        admins.Element = AAZStrType()

        database = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_admin.database
        database.host = AAZStrType(
            flags={"required": True},
        )
        database.name = AAZStrType(
            flags={"required": True},
        )
        database.password_secret_ref = AAZStrType(
            serialized_name="passwordSecretRef",
        )
        database.username = AAZStrType()

        ranger_audit = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_audit
        ranger_audit.storage_account = AAZStrType(
            serialized_name="storageAccount",
        )

        ranger_usersync = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_usersync
        ranger_usersync.enabled = AAZBoolType()
        ranger_usersync.groups = AAZListType()
        ranger_usersync.mode = AAZStrType()
        ranger_usersync.user_mapping_location = AAZStrType(
            serialized_name="userMappingLocation",
        )
        ranger_usersync.users = AAZListType()

        groups = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_usersync.groups
        groups.Element = AAZStrType()

        users = _schema_cluster_read.properties.cluster_profile.ranger_profile.ranger_usersync.users
        users.Element = AAZStrType()

        script_action_profiles = _schema_cluster_read.properties.cluster_profile.script_action_profiles
        script_action_profiles.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.script_action_profiles.Element
        _element.name = AAZStrType(
            flags={"required": True},
        )
        _element.parameters = AAZStrType()
        _element.services = AAZListType(
            flags={"required": True},
        )
        _element.should_persist = AAZBoolType(
            serialized_name="shouldPersist",
        )
        _element.timeout_in_minutes = AAZIntType(
            serialized_name="timeoutInMinutes",
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.url = AAZStrType(
            flags={"required": True},
        )

        services = _schema_cluster_read.properties.cluster_profile.script_action_profiles.Element.services
        services.Element = AAZStrType()

        secrets_profile = _schema_cluster_read.properties.cluster_profile.secrets_profile
        secrets_profile.key_vault_resource_id = AAZStrType(
            serialized_name="keyVaultResourceId",
            flags={"required": True},
        )
        secrets_profile.secrets = AAZListType()

        secrets = _schema_cluster_read.properties.cluster_profile.secrets_profile.secrets
        secrets.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.secrets_profile.secrets.Element
        _element.key_vault_object_name = AAZStrType(
            serialized_name="keyVaultObjectName",
            flags={"required": True},
        )
        _element.reference_name = AAZStrType(
            serialized_name="referenceName",
            flags={"required": True},
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.version = AAZStrType()

        service_configs_profiles = _schema_cluster_read.properties.cluster_profile.service_configs_profiles
        service_configs_profiles.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element
        _element.configs = AAZListType(
            flags={"required": True},
        )
        _element.service_name = AAZStrType(
            serialized_name="serviceName",
            flags={"required": True},
        )

        configs = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs
        configs.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element
        _element.component = AAZStrType(
            flags={"required": True},
        )
        _element.files = AAZListType(
            flags={"required": True},
        )

        files = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files
        files.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files.Element
        _element.content = AAZStrType()
        _element.encoding = AAZStrType()
        _element.file_name = AAZStrType(
            serialized_name="fileName",
            flags={"required": True},
        )
        _element.path = AAZStrType()
        _element.values = AAZDictType()

        values = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files.Element.values
        values.Element = AAZStrType()

        spark_profile = _schema_cluster_read.properties.cluster_profile.spark_profile
        spark_profile.default_storage_url = AAZStrType(
            serialized_name="defaultStorageUrl",
        )
        spark_profile.metastore_spec = AAZObjectType(
            serialized_name="metastoreSpec",
        )
        spark_profile.user_plugins_spec = AAZObjectType(
            serialized_name="userPluginsSpec",
        )

        metastore_spec = _schema_cluster_read.properties.cluster_profile.spark_profile.metastore_spec
        metastore_spec.db_connection_authentication_mode = AAZStrType(
            serialized_name="dbConnectionAuthenticationMode",
        )
        metastore_spec.db_name = AAZStrType(
            serialized_name="dbName",
            flags={"required": True},
        )
        metastore_spec.db_password_secret_name = AAZStrType(
            serialized_name="dbPasswordSecretName",
        )
        metastore_spec.db_server_host = AAZStrType(
            serialized_name="dbServerHost",
            flags={"required": True},
        )
        metastore_spec.db_user_name = AAZStrType(
            serialized_name="dbUserName",
        )
        metastore_spec.key_vault_id = AAZStrType(
            serialized_name="keyVaultId",
        )
        metastore_spec.thrift_url = AAZStrType(
            serialized_name="thriftUrl",
        )

        user_plugins_spec = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec
        user_plugins_spec.plugins = AAZListType()

        plugins = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec.plugins
        plugins.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec.plugins.Element
        _element.path = AAZStrType(
            flags={"required": True},
        )

        ssh_profile = _schema_cluster_read.properties.cluster_profile.ssh_profile
        ssh_profile.count = AAZIntType(
            flags={"required": True},
        )
        ssh_profile.pod_prefix = AAZStrType(
            serialized_name="podPrefix",
            flags={"read_only": True},
        )
        ssh_profile.vm_size = AAZStrType(
            serialized_name="vmSize",
        )

        trino_profile = _schema_cluster_read.properties.cluster_profile.trino_profile
        trino_profile.catalog_options = AAZObjectType(
            serialized_name="catalogOptions",
        )
        trino_profile.coordinator = AAZObjectType()
        trino_profile.user_plugins_spec = AAZObjectType(
            serialized_name="userPluginsSpec",
        )
        trino_profile.user_telemetry_spec = AAZObjectType(
            serialized_name="userTelemetrySpec",
        )
        trino_profile.worker = AAZObjectType()

        catalog_options = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options
        catalog_options.hive = AAZListType()

        hive = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options.hive
        hive.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options.hive.Element
        _element.catalog_name = AAZStrType(
            serialized_name="catalogName",
            flags={"required": True},
        )
        _element.metastore_db_connection_authentication_mode = AAZStrType(
            serialized_name="metastoreDbConnectionAuthenticationMode",
        )
        _element.metastore_db_connection_password_secret = AAZStrType(
            serialized_name="metastoreDbConnectionPasswordSecret",
        )
        _element.metastore_db_connection_url = AAZStrType(
            serialized_name="metastoreDbConnectionURL",
            flags={"required": True},
        )
        _element.metastore_db_connection_user_name = AAZStrType(
            serialized_name="metastoreDbConnectionUserName",
        )
        _element.metastore_warehouse_dir = AAZStrType(
            serialized_name="metastoreWarehouseDir",
            flags={"required": True},
        )

        coordinator = _schema_cluster_read.properties.cluster_profile.trino_profile.coordinator
        coordinator.debug = AAZObjectType(
            flags={"client_flatten": True},
        )
        cls._build_schema_trino_debug_config_read(coordinator.debug)
        coordinator.high_availability_enabled = AAZBoolType(
            serialized_name="highAvailabilityEnabled",
        )

        user_plugins_spec = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec
        user_plugins_spec.plugins = AAZListType()

        plugins = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec.plugins
        plugins.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec.plugins.Element
        _element.enabled = AAZBoolType()
        _element.name = AAZStrType()
        _element.path = AAZStrType()

        user_telemetry_spec = _schema_cluster_read.properties.cluster_profile.trino_profile.user_telemetry_spec
        user_telemetry_spec.storage = AAZObjectType()

        storage = _schema_cluster_read.properties.cluster_profile.trino_profile.user_telemetry_spec.storage
        storage.hivecatalog_name = AAZStrType(
            serialized_name="hivecatalogName",
        )
        storage.hivecatalog_schema = AAZStrType(
            serialized_name="hivecatalogSchema",
        )
        storage.partition_retention_in_days = AAZIntType(
            serialized_name="partitionRetentionInDays",
        )
        storage.path = AAZStrType()

        worker = _schema_cluster_read.properties.cluster_profile.trino_profile.worker
        worker.debug = AAZObjectType(
            flags={"client_flatten": True},
        )
        cls._build_schema_trino_debug_config_read(worker.debug)

        compute_profile = _schema_cluster_read.properties.compute_profile
        compute_profile.nodes = AAZListType(
            flags={"required": True},
        )

        nodes = _schema_cluster_read.properties.compute_profile.nodes
        nodes.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.compute_profile.nodes.Element
        _element.count = AAZIntType(
            flags={"required": True},
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.vm_size = AAZStrType(
            serialized_name="vmSize",
            flags={"required": True},
        )

        system_data = _schema_cluster_read.system_data
        system_data.created_at = AAZStrType(
            serialized_name="createdAt",
        )
        system_data.created_by = AAZStrType(
            serialized_name="createdBy",
        )
        system_data.created_by_type = AAZStrType(
            serialized_name="createdByType",
        )
        system_data.last_modified_at = AAZStrType(
            serialized_name="lastModifiedAt",
        )
        system_data.last_modified_by = AAZStrType(
            serialized_name="lastModifiedBy",
        )
        system_data.last_modified_by_type = AAZStrType(
            serialized_name="lastModifiedByType",
        )

        tags = _schema_cluster_read.tags
        tags.Element = AAZStrType()

        _schema.id = cls._schema_cluster_read.id
        _schema.location = cls._schema_cluster_read.location
        _schema.name = cls._schema_cluster_read.name
        _schema.properties = cls._schema_cluster_read.properties
        _schema.system_data = cls._schema_cluster_read.system_data
        _schema.tags = cls._schema_cluster_read.tags
        _schema.type = cls._schema_cluster_read.type

    _schema_compute_resource_definition_read = None

    @classmethod
    def _build_schema_compute_resource_definition_read(cls, _schema):
        if cls._schema_compute_resource_definition_read is not None:
            _schema.cpu = cls._schema_compute_resource_definition_read.cpu
            _schema.memory = cls._schema_compute_resource_definition_read.memory
            return

        cls._schema_compute_resource_definition_read = _schema_compute_resource_definition_read = AAZObjectType()

        compute_resource_definition_read = _schema_compute_resource_definition_read
        compute_resource_definition_read.cpu = AAZFloatType(
            flags={"required": True},
        )
        compute_resource_definition_read.memory = AAZIntType(
            flags={"required": True},
        )

        _schema.cpu = cls._schema_compute_resource_definition_read.cpu
        _schema.memory = cls._schema_compute_resource_definition_read.memory

    _schema_trino_debug_config_read = None

    @classmethod
    def _build_schema_trino_debug_config_read(cls, _schema):
        if cls._schema_trino_debug_config_read is not None:
            _schema.enable = cls._schema_trino_debug_config_read.enable
            _schema.port = cls._schema_trino_debug_config_read.port
            _schema.suspend = cls._schema_trino_debug_config_read.suspend
            return

        cls._schema_trino_debug_config_read = _schema_trino_debug_config_read = AAZObjectType()

        trino_debug_config_read = _schema_trino_debug_config_read
        trino_debug_config_read.enable = AAZBoolType()
        trino_debug_config_read.port = AAZIntType()
        trino_debug_config_read.suspend = AAZBoolType()

        _schema.enable = cls._schema_trino_debug_config_read.enable
        _schema.port = cls._schema_trino_debug_config_read.port
        _schema.suspend = cls._schema_trino_debug_config_read.suspend


__all__ = ["Update"]
