# --------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
#
# Code generated by aaz-dev-tools
# --------------------------------------------------------------------------------------------

# pylint: skip-file
# flake8: noqa

from azure.cli.core.aaz import *


@register_command(
    "hdinsightonaks cluster update",
    is_preview=True,
)
class Update(AAZCommand):
    """Update a cluster.
    """

    _aaz_info = {
        "version": "2023-06-01-preview",
        "resources": [
            ["mgmt-plane", "/subscriptions/{}/resourcegroups/{}/providers/microsoft.hdinsight/clusterpools/{}/clusters/{}", "2023-06-01-preview"],
        ]
    }

    AZ_SUPPORT_NO_WAIT = True

    AZ_SUPPORT_GENERIC_UPDATE = True

    def _handler(self, command_args):
        super()._handler(command_args)
        return self.build_lro_poller(self._execute_operations, self._output)

    _args_schema = None

    @classmethod
    def _build_arguments_schema(cls, *args, **kwargs):
        if cls._args_schema is not None:
            return cls._args_schema
        cls._args_schema = super()._build_arguments_schema(*args, **kwargs)

        # define Arg Group ""

        _args_schema = cls._args_schema
        _args_schema.cluster_name = AAZStrArg(
            options=["-n", "--name", "--cluster-name"],
            help="The name of the HDInsight cluster.",
            required=True,
            id_part="child_name_1",
        )
        _args_schema.cluster_pool_name = AAZStrArg(
            options=["--cluster-pool-name"],
            help="The name of the cluster pool.",
            required=True,
            id_part="name",
        )
        _args_schema.resource_group = AAZResourceGroupNameArg(
            required=True,
        )

        # define Arg Group "ClusterProfile"

        _args_schema = cls._args_schema
        _args_schema.authorization_group_id = AAZListArg(
            options=["--authorization-group-id"],
            arg_group="ClusterProfile",
            help="AAD group Ids authorized for data plane access.",
            nullable=True,
        )
        _args_schema.authorization_user_id = AAZListArg(
            options=["--authorization-user-id"],
            arg_group="ClusterProfile",
            help="AAD user Ids authorized for data plane access.",
            nullable=True,
        )
        _args_schema.autoscale_profile_type = AAZStrArg(
            options=["--autoscale-profile-type"],
            arg_group="ClusterProfile",
            help="User to specify which type of Autoscale to be implemented - Scheduled Based or Load Based.",
            nullable=True,
            enum={"LoadBased": "LoadBased", "ScheduleBased": "ScheduleBased"},
        )
        _args_schema.autoscale_profile_enabled = AAZBoolArg(
            options=["--autoscale-profile-enabled"],
            arg_group="ClusterProfile",
            help="This indicates whether auto scale is enabled on HDInsight on AKS cluster.",
        )
        _args_schema.autoscale_profile_graceful_decommission_timeout = AAZIntArg(
            options=["--autoscale-profile-graceful-decommission-timeout"],
            arg_group="ClusterProfile",
            help="This property is for graceful decommission timeout; It has a default setting of 3600 seconds before forced shutdown takes place. This is the maximal time to wait for running containers and applications to complete before transition a DECOMMISSIONING node into DECOMMISSIONED. The default value is 3600 seconds. Negative value (like -1) is handled as infinite timeout.",
            nullable=True,
        )
        _args_schema.loadbased_config_cooldown_period = AAZIntArg(
            options=["--loadbased-config-cooldown-period"],
            arg_group="ClusterProfile",
            help="This is a cool down period, this is a time period in seconds, which determines the amount of time that must elapse between a scaling activity started by a rule and the start of the next scaling activity, regardless of the rule that triggers it. The default value is 300 seconds.",
            nullable=True,
        )
        _args_schema.loadbased_config_max_nodes = AAZIntArg(
            options=["--loadbased-config-max-nodes"],
            arg_group="ClusterProfile",
            help="User needs to set the maximum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.",
        )
        _args_schema.loadbased_config_min_nodes = AAZIntArg(
            options=["--loadbased-config-min-nodes"],
            arg_group="ClusterProfile",
            help="User needs to set the minimum number of nodes for load based scaling, the load based scaling will use this to scale up and scale down between minimum and maximum number of nodes.",
        )
        _args_schema.loadbased_config_poll_interval = AAZIntArg(
            options=["--loadbased-config-poll-interval"],
            arg_group="ClusterProfile",
            help="User can specify the poll interval, this is the time period (in seconds) after which scaling metrics are polled for triggering a scaling operation.",
            nullable=True,
        )
        _args_schema.loadbased_config_scaling_rules = AAZListArg(
            options=["--loadbased-config-scaling-rules"],
            arg_group="ClusterProfile",
            help="The scaling rules.",
        )
        _args_schema.schedule_based_config_default_count = AAZIntArg(
            options=["--schedule-based-config-default-count"],
            arg_group="ClusterProfile",
            help="Setting default node count of current schedule configuration. Default node count specifies the number of nodes which are default when an specified scaling operation is executed (scale up/scale down)",
        )
        _args_schema.schedule_based_config_schedule = AAZListArg(
            options=["--schedule-based-config-schedule"],
            arg_group="ClusterProfile",
            help="This specifies the schedules where scheduled based Autoscale to be enabled, the user has a choice to set multiple rules within the schedule across days and times (start/end).",
        )
        _args_schema.schedule_based_config_time_zone = AAZStrArg(
            options=["--schedule-based-config-time-zone"],
            arg_group="ClusterProfile",
            help="User has to specify the timezone on which the schedule has to be set for schedule based autoscale configuration.",
        )
        _args_schema.cluster_version = AAZStrArg(
            options=["--cluster-version"],
            arg_group="ClusterProfile",
            help="Version with 3/4 part.",
            fmt=AAZStrArgFormat(
                pattern="^(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})(?:\.(0|[1-9][0-9]{0,18}))?$",
            ),
        )
        _args_schema.assigned_identity_client_id = AAZStrArg(
            options=["--assigned-identity-client-id"],
            arg_group="ClusterProfile",
            help="ClientId of the MSI.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _args_schema.assigned_identity_object_id = AAZStrArg(
            options=["--assigned-identity-object-id"],
            arg_group="ClusterProfile",
            help="ObjectId of the MSI.",
            fmt=AAZStrArgFormat(
                pattern="^[{(]?[0-9A-Fa-f]{8}[-]?(?:[0-9A-Fa-f]{4}[-]?){3}[0-9A-Fa-f]{12}[)}]?$",
            ),
        )
        _args_schema.assigned_identity_resource_id = AAZResourceIdArg(
            options=["--assigned-identity-resource-id"],
            arg_group="ClusterProfile",
            help="ResourceId of the MSI.",
        )
        _args_schema.kafka_profile = AAZFreeFormDictArg(
            options=["--kafka-profile"],
            arg_group="ClusterProfile",
            help="Kafka cluster profile.",
            nullable=True,
        )
        _args_schema.llap_profile = AAZFreeFormDictArg(
            options=["--llap-profile"],
            arg_group="ClusterProfile",
            help="LLAP cluster profile.",
            nullable=True,
        )
        _args_schema.application_log_std_error_enabled = AAZBoolArg(
            options=["--application-log-std-error-enabled"],
            arg_group="ClusterProfile",
            help="True if stderror is enabled, otherwise false.",
            nullable=True,
        )
        _args_schema.application_log_std_out_enabled = AAZBoolArg(
            options=["--application-log-std-out-enabled"],
            arg_group="ClusterProfile",
            help="True if stdout is enabled, otherwise false.",
            nullable=True,
        )
        _args_schema.enable_log_analytics = AAZBoolArg(
            options=["--enable-log-analytics"],
            arg_group="ClusterProfile",
            help="True if log analytics is enabled for the cluster, otherwise false.",
        )
        _args_schema.log_analytic_profile_metrics_enabled = AAZBoolArg(
            options=["--log-analytic-profile-metrics-enabled"],
            arg_group="ClusterProfile",
            help="True if metrics are enabled, otherwise false.",
            nullable=True,
        )
        _args_schema.oss_version = AAZStrArg(
            options=["--oss-version"],
            arg_group="ClusterProfile",
            help="Version with three part.",
            fmt=AAZStrArgFormat(
                pattern="^(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})\.(0|[1-9][0-9]{0,18})$",
            ),
        )
        _args_schema.prometheu_profile_enabled = AAZBoolArg(
            options=["--prometheu-profile-enabled"],
            arg_group="ClusterProfile",
            help="Enable Prometheus for cluster or not.",
        )
        _args_schema.script_action_profiles = AAZListArg(
            options=["--script-action-profiles"],
            arg_group="ClusterProfile",
            help="The script action profile list.",
            nullable=True,
        )
        _args_schema.service_configs_profiles = AAZListArg(
            options=["--service-configs-profiles"],
            arg_group="ClusterProfile",
            help="The service configs profiles.",
            nullable=True,
        )
        _args_schema.spark_storage_url = AAZStrArg(
            options=["--spark-storage-url"],
            arg_group="ClusterProfile",
            help="The default storage URL.",
            nullable=True,
        )
        _args_schema.spark_hive_catalog_db_name = AAZStrArg(
            options=["--spark-hive-catalog-db-name"],
            arg_group="ClusterProfile",
            help="The database name.",
        )
        _args_schema.spark_hive_catalog_db_password_secret_name = AAZStrArg(
            options=["--spark-hive-catalog-db-password-secret-name"],
            arg_group="ClusterProfile",
            help="The secret name which contains the database user password.",
        )
        _args_schema.spark_hive_catalog_db_server_name = AAZStrArg(
            options=["--spark-hive-catalog-db-server-name"],
            arg_group="ClusterProfile",
            help="The database server host.",
        )
        _args_schema.spark_hive_catalog_db_user_name = AAZStrArg(
            options=["--spark-hive-catalog-db-user-name"],
            arg_group="ClusterProfile",
            help="The database user name.",
        )
        _args_schema.spark_hive_catalog_key_vault_id = AAZStrArg(
            options=["--spark-hive-catalog-key-vault-id"],
            arg_group="ClusterProfile",
            help="The key vault resource id.",
        )
        _args_schema.spark_hive_catalog_thrift_url = AAZStrArg(
            options=["--spark-hive-catalog-thrift-url"],
            arg_group="ClusterProfile",
            help="The thrift url.",
            nullable=True,
        )
        _args_schema.user_plugins_spec = AAZObjectArg(
            options=["--user-plugins-spec"],
            arg_group="ClusterProfile",
            help="Spark user plugins spec",
            nullable=True,
        )
        _args_schema.ssh_profile_count = AAZIntArg(
            options=["--ssh-profile-count"],
            arg_group="ClusterProfile",
            help="Number of ssh pods per cluster.",
            fmt=AAZIntArgFormat(
                maximum=5,
                minimum=0,
            ),
        )
        _args_schema.stub_profile = AAZFreeFormDictArg(
            options=["--stub-profile"],
            arg_group="ClusterProfile",
            help="Stub cluster profile.",
            nullable=True,
        )
        _args_schema.trino_profile = AAZObjectArg(
            options=["--trino-profile"],
            arg_group="ClusterProfile",
            help="Trino Cluster profile.",
            nullable=True,
        )

        authorization_group_id = cls._args_schema.authorization_group_id
        authorization_group_id.Element = AAZStrArg(
            nullable=True,
        )

        authorization_user_id = cls._args_schema.authorization_user_id
        authorization_user_id.Element = AAZStrArg(
            nullable=True,
        )

        loadbased_config_scaling_rules = cls._args_schema.loadbased_config_scaling_rules
        loadbased_config_scaling_rules.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.loadbased_config_scaling_rules.Element
        _element.action_type = AAZStrArg(
            options=["action-type"],
            help="The action type.",
            enum={"scaledown": "scaledown", "scaleup": "scaleup"},
        )
        _element.comparison_rule = AAZObjectArg(
            options=["comparison-rule"],
            help="The comparison rule.",
        )
        _element.evaluation_count = AAZIntArg(
            options=["evaluation-count"],
            help="This is an evaluation count for a scaling condition, the number of times a trigger condition should be successful, before scaling activity is triggered.",
        )
        _element.scaling_metric = AAZStrArg(
            options=["scaling-metric"],
            help="Metrics name for individual workloads. For example: cpu",
        )

        comparison_rule = cls._args_schema.loadbased_config_scaling_rules.Element.comparison_rule
        comparison_rule.operator = AAZStrArg(
            options=["operator"],
            help="The comparison operator.",
            enum={"greaterThan": "greaterThan", "greaterThanOrEqual": "greaterThanOrEqual", "lessThan": "lessThan", "lessThanOrEqual": "lessThanOrEqual"},
        )
        comparison_rule.threshold = AAZFloatArg(
            options=["threshold"],
            help="Threshold setting.",
        )

        schedule_based_config_schedule = cls._args_schema.schedule_based_config_schedule
        schedule_based_config_schedule.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.schedule_based_config_schedule.Element
        _element.count = AAZIntArg(
            options=["count"],
            help="User has to set the node count anticipated at end of the scaling operation of the set current schedule configuration, format is integer.",
        )
        _element.days = AAZListArg(
            options=["days"],
            help="User has to set the days where schedule has to be set for autoscale operation.",
        )
        _element.end_time = AAZStrArg(
            options=["end-time"],
            help="User has to set the end time of current schedule configuration, format like 10:30 (HH:MM).",
            fmt=AAZStrArgFormat(
                pattern="^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$",
            ),
        )
        _element.start_time = AAZStrArg(
            options=["start-time"],
            help="User has to set the start time of current schedule configuration, format like 10:30 (HH:MM).",
            fmt=AAZStrArgFormat(
                pattern="^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$",
            ),
        )

        days = cls._args_schema.schedule_based_config_schedule.Element.days
        days.Element = AAZStrArg(
            nullable=True,
            enum={"Friday": "Friday", "Monday": "Monday", "Saturday": "Saturday", "Sunday": "Sunday", "Thursday": "Thursday", "Tuesday": "Tuesday", "Wednesday": "Wednesday"},
        )

        script_action_profiles = cls._args_schema.script_action_profiles
        script_action_profiles.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.script_action_profiles.Element
        _element.name = AAZStrArg(
            options=["name"],
            help="Script name.",
        )
        _element.parameters = AAZStrArg(
            options=["parameters"],
            help="Additional parameters for the script action. It should be space-separated list of arguments required for script execution.",
            nullable=True,
        )
        _element.services = AAZListArg(
            options=["services"],
            help="List of services to apply the script action.",
        )
        _element.should_persist = AAZBoolArg(
            options=["should-persist"],
            help="Specify if the script should persist on the cluster.",
            nullable=True,
        )
        _element.timeout_in_minutes = AAZIntArg(
            options=["timeout-in-minutes"],
            help="Timeout duration for the script action in minutes.",
            nullable=True,
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="Type of the script action. Supported type is bash scripts.",
        )
        _element.url = AAZStrArg(
            options=["url"],
            help="Url of the script file.",
            fmt=AAZStrArgFormat(
                pattern="^(https)|(http)|(abfss)|(abfs)|(wasbs)|(wasb)://.*$",
            ),
        )

        services = cls._args_schema.script_action_profiles.Element.services
        services.Element = AAZStrArg(
            nullable=True,
        )

        service_configs_profiles = cls._args_schema.service_configs_profiles
        service_configs_profiles.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element
        _element.configs = AAZListArg(
            options=["configs"],
            help="List of service configs.",
        )
        _element.service_name = AAZStrArg(
            options=["service-name"],
            help="Name of the service the configurations should apply to.",
        )

        configs = cls._args_schema.service_configs_profiles.Element.configs
        configs.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element.configs.Element
        _element.component = AAZStrArg(
            options=["component"],
            help="Name of the component the config files should apply to.",
        )
        _element.files = AAZListArg(
            options=["files"],
            help="List of Config Files.",
        )

        files = cls._args_schema.service_configs_profiles.Element.configs.Element.files
        files.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.service_configs_profiles.Element.configs.Element.files.Element
        _element.content = AAZStrArg(
            options=["content"],
            help="Free form content of the entire configuration file.",
            nullable=True,
        )
        _element.encoding = AAZStrArg(
            options=["encoding"],
            help="This property indicates if the content is encoded and is case-insensitive. Please set the value to base64 if the content is base64 encoded. Set it to none or skip it if the content is plain text.",
            nullable=True,
            enum={"Base64": "Base64", "None": "None"},
        )
        _element.file_name = AAZStrArg(
            options=["file-name"],
            help="Configuration file name.",
        )
        _element.path = AAZStrArg(
            options=["path"],
            help="Path of the config file if content is specified.",
            nullable=True,
        )
        _element.values = AAZDictArg(
            options=["values"],
            help="List of key value pairs where key represents a valid service configuration name and value represents the value of the config.",
            nullable=True,
        )

        values = cls._args_schema.service_configs_profiles.Element.configs.Element.files.Element.values
        values.Element = AAZStrArg(
            nullable=True,
        )

        user_plugins_spec = cls._args_schema.user_plugins_spec
        user_plugins_spec.plugins = AAZListArg(
            options=["plugins"],
            help="Spark user plugins.",
            nullable=True,
        )

        plugins = cls._args_schema.user_plugins_spec.plugins
        plugins.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.user_plugins_spec.plugins.Element
        _element.path = AAZStrArg(
            options=["path"],
            help="Fully qualified path to the folder containing the plugins.",
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )

        trino_profile = cls._args_schema.trino_profile
        trino_profile.catalog_options = AAZObjectArg(
            options=["catalog-options"],
            help="Trino cluster catalog options.",
            nullable=True,
        )
        trino_profile.coordinator_high_availability_enabled = AAZBoolArg(
            options=["coordinator-high-availability-enabled"],
            nullable=True,
        )
        trino_profile.coordinator_debug_port = AAZIntArg(
            options=["coordinator-debug-port"],
            nullable=True,
        )
        trino_profile.coordinator_debug_suspend = AAZBoolArg(
            options=["coordinator-debug-suspend"],
            nullable=True,
        )
        trino_profile.coordinator_debug_enabled = AAZBoolArg(
            options=["coordinator-debug-enabled"],
            help="The flag that if enable coordinator HA, uses multiple coordinator replicas with auto failover, one per each head node. Default: true.",
            nullable=True,
        )
        trino_profile.user_plugins_spec = AAZObjectArg(
            options=["user-plugins-spec"],
            help="Trino user plugins spec",
            nullable=True,
        )
        trino_profile.user_telemetry_spec = AAZObjectArg(
            options=["user-telemetry-spec"],
            help="User telemetry",
            nullable=True,
        )
        trino_profile.worker = AAZObjectArg(
            options=["worker"],
            help="Trino worker.",
            nullable=True,
        )

        catalog_options = cls._args_schema.trino_profile.catalog_options
        catalog_options.hive = AAZListArg(
            options=["hive"],
            help="hive catalog options.",
            nullable=True,
        )

        hive = cls._args_schema.trino_profile.catalog_options.hive
        hive.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.trino_profile.catalog_options.hive.Element
        _element.catalog_name = AAZStrArg(
            options=["catalog-name"],
            help="Name of trino catalog which should use specified hive metastore.",
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        _element.metastore_db_connection_password_secret = AAZStrArg(
            options=["metastore-db-connection-password-secret"],
            help="Secret reference name from secretsProfile.secrets containing password for database connection.",
        )
        _element.metastore_db_connection_url = AAZStrArg(
            options=["metastore-db-connection-url"],
            help="Connection string for hive metastore database.",
        )
        _element.metastore_db_connection_user_name = AAZStrArg(
            options=["metastore-db-connection-user-name"],
            help="User name for database connection.",
        )
        _element.metastore_warehouse_dir = AAZStrArg(
            options=["metastore-warehouse-dir"],
            help="Metastore root directory URI, format: abfs[s]://<container>@<account_name>.dfs.core.windows.net/<path>. More details: https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction-abfs-uri",
        )

        user_plugins_spec = cls._args_schema.trino_profile.user_plugins_spec
        user_plugins_spec.plugins = AAZListArg(
            options=["plugins"],
            help="Trino user plugins.",
            nullable=True,
        )

        plugins = cls._args_schema.trino_profile.user_plugins_spec.plugins
        plugins.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.trino_profile.user_plugins_spec.plugins.Element
        _element.enabled = AAZBoolArg(
            options=["enabled"],
            help="Denotes whether the plugin is active or not.",
            nullable=True,
        )
        _element.name = AAZStrArg(
            options=["name"],
            help="This field maps to the sub-directory in trino plugins location, that will contain all the plugins under path.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        _element.path = AAZStrArg(
            options=["path"],
            help="Fully qualified path to the folder containing the plugins.",
            nullable=True,
            fmt=AAZStrArgFormat(
                pattern="^(https)|(abfss)://.*$",
                min_length=1,
            ),
        )

        user_telemetry_spec = cls._args_schema.trino_profile.user_telemetry_spec
        user_telemetry_spec.storage = AAZObjectArg(
            options=["storage"],
            help="Trino user telemetry definition.",
            nullable=True,
        )

        storage = cls._args_schema.trino_profile.user_telemetry_spec.storage
        storage.hivecatalog_name = AAZStrArg(
            options=["hivecatalog-name"],
            help="Hive Catalog name used to mount external tables on the logs written by trino, if not specified there tables are not created.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )
        storage.hivecatalog_schema = AAZStrArg(
            options=["hivecatalog-schema"],
            help="Schema of the above catalog to use, to mount query logs as external tables, if not specified tables will be mounted under schema trinologs.",
            nullable=True,
        )
        storage.partition_retention_in_days = AAZIntArg(
            options=["partition-retention-in-days"],
            help="Retention period for query log table partitions, this doesn't have any affect on actual data.",
            nullable=True,
        )
        storage.path = AAZStrArg(
            options=["path"],
            help="Azure storage location of the blobs.",
            nullable=True,
            fmt=AAZStrArgFormat(
                min_length=1,
            ),
        )

        worker = cls._args_schema.trino_profile.worker
        worker.debug = AAZObjectArg(
            options=["debug"],
            nullable=True,
        )
        cls._build_args_trino_debug_config_update(worker.debug)

        # define Arg Group "ComputeProfile"

        _args_schema = cls._args_schema
        _args_schema.nodes = AAZListArg(
            options=["--nodes"],
            arg_group="ComputeProfile",
            help="The nodes definitions.",
        )

        nodes = cls._args_schema.nodes
        nodes.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.nodes.Element
        _element.count = AAZIntArg(
            options=["count"],
            help="The number of virtual machines.",
            fmt=AAZIntArgFormat(
                minimum=1,
            ),
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="The node type.",
            fmt=AAZStrArgFormat(
                pattern="^(head|Head|HEAD|worker|Worker|WORKER)$",
            ),
        )
        _element.vm_size = AAZStrArg(
            options=["vm-size"],
            help="The virtual machine SKU.",
            fmt=AAZStrArgFormat(
                pattern="^[a-zA-Z0-9_\-]{0,256}$",
            ),
        )

        # define Arg Group "FlinkProfile"

        _args_schema = cls._args_schema
        _args_schema.flink_hive_catalog_db_connection_password_secret = AAZStrArg(
            options=["--flink-hive-catalog-db-connection-password-secret"],
            arg_group="FlinkProfile",
            help="Secret reference name from secretsProfile.secrets containing password for database connection.",
        )
        _args_schema.flink_hive_catalog_db_connection_url = AAZStrArg(
            options=["--flink-hive-catalog-db-connection-url"],
            arg_group="FlinkProfile",
            help="Connection string for hive metastore database.",
        )
        _args_schema.flink_hive_catalog_db_connection_user_name = AAZStrArg(
            options=["--flink-hive-catalog-db-connection-user-name"],
            arg_group="FlinkProfile",
            help="User name for database connection.",
        )
        _args_schema.history_server_cpu = AAZFloatArg(
            options=["--history-server-cpu"],
            arg_group="FlinkProfile",
            help="History server cpu count.",
        )
        _args_schema.history_server_memory = AAZIntArg(
            options=["--history-server-memory"],
            arg_group="FlinkProfile",
            help="History server memory size.",
        )
        _args_schema.job_manager_cpu = AAZFloatArg(
            options=["--job-manager-cpu"],
            arg_group="FlinkProfile",
            help="Job manager CPU count.",
        )
        _args_schema.job_manager_memory = AAZIntArg(
            options=["--job-manager-memory"],
            arg_group="FlinkProfile",
            help="Job manager memory size.",
        )
        _args_schema.num_replicas = AAZIntArg(
            options=["--num-replicas"],
            arg_group="FlinkProfile",
            help="The number of task managers.",
            nullable=True,
        )
        _args_schema.flink_storage_uri = AAZStrArg(
            options=["--flink-storage-uri"],
            arg_group="FlinkProfile",
            help="Storage account uri which is used for savepoint and checkpoint state.",
            fmt=AAZStrArgFormat(
                pattern="^(\w{4,5})://(.*)@(.*).\b(blob|dfs)\b\.core\.windows\.net$",
            ),
        )
        _args_schema.flink_storage_key = AAZStrArg(
            options=["--flink-storage-key"],
            arg_group="FlinkProfile",
            help="Storage key is only required for wasb(s) storage.",
            nullable=True,
        )
        _args_schema.task_manager_cpu = AAZFloatArg(
            options=["--task-manager-cpu"],
            arg_group="FlinkProfile",
        )
        _args_schema.task_manager_memory = AAZIntArg(
            options=["--task-manager-memory"],
            arg_group="FlinkProfile",
        )

        # define Arg Group "HDInsightCluster"

        _args_schema = cls._args_schema
        _args_schema.tags = AAZDictArg(
            options=["--tags"],
            arg_group="HDInsightCluster",
            help="Resource tags.",
            nullable=True,
        )

        tags = cls._args_schema.tags
        tags.Element = AAZStrArg(
            nullable=True,
        )

        # define Arg Group "SecretsProfile"

        _args_schema = cls._args_schema
        _args_schema.key_vault_id = AAZResourceIdArg(
            options=["--key-vault-id"],
            arg_group="SecretsProfile",
            help="Name of the user Key Vault where all the cluster specific user secrets are stored.",
        )
        _args_schema.secret_reference = AAZListArg(
            options=["--secret-reference"],
            arg_group="SecretsProfile",
            help="Properties of Key Vault secret.",
            nullable=True,
        )

        secret_reference = cls._args_schema.secret_reference
        secret_reference.Element = AAZObjectArg(
            nullable=True,
        )

        _element = cls._args_schema.secret_reference.Element
        _element.secret_name = AAZStrArg(
            options=["secret-name"],
            help="Object identifier name of the secret in key vault.",
            fmt=AAZStrArgFormat(
                pattern="^[a-zA-Z][a-zA-Z0-9-]{1,126}$",
            ),
        )
        _element.reference_name = AAZStrArg(
            options=["reference-name"],
            help="Reference name of the secret to be used in service configs.",
        )
        _element.type = AAZStrArg(
            options=["type"],
            help="Type of key vault object: secret, key or certificate.",
            enum={"Certificate": "Certificate", "Key": "Key", "Secret": "Secret"},
        )
        _element.version = AAZStrArg(
            options=["version"],
            help="Version of the secret in key vault.",
            nullable=True,
        )
        return cls._args_schema

    _args_trino_debug_config_update = None

    @classmethod
    def _build_args_trino_debug_config_update(cls, _schema):
        if cls._args_trino_debug_config_update is not None:
            _schema.enable = cls._args_trino_debug_config_update.enable
            _schema.port = cls._args_trino_debug_config_update.port
            _schema.suspend = cls._args_trino_debug_config_update.suspend
            return

        cls._args_trino_debug_config_update = AAZObjectArg(
            nullable=True,
        )

        trino_debug_config_update = cls._args_trino_debug_config_update
        trino_debug_config_update.enable = AAZBoolArg(
            options=["enable"],
            help="The flag that if enable debug or not.",
            nullable=True,
        )
        trino_debug_config_update.port = AAZIntArg(
            options=["port"],
            help="The debug port.",
            nullable=True,
        )
        trino_debug_config_update.suspend = AAZBoolArg(
            options=["suspend"],
            help="The flag that if suspend debug or not.",
            nullable=True,
        )

        _schema.enable = cls._args_trino_debug_config_update.enable
        _schema.port = cls._args_trino_debug_config_update.port
        _schema.suspend = cls._args_trino_debug_config_update.suspend

    def _execute_operations(self):
        self.pre_operations()
        self.ClustersGet(ctx=self.ctx)()
        self.pre_instance_update(self.ctx.vars.instance)
        self.InstanceUpdateByJson(ctx=self.ctx)()
        self.InstanceUpdateByGeneric(ctx=self.ctx)()
        self.post_instance_update(self.ctx.vars.instance)
        yield self.ClustersCreate(ctx=self.ctx)()
        self.post_operations()

    @register_callback
    def pre_operations(self):
        pass

    @register_callback
    def post_operations(self):
        pass

    @register_callback
    def pre_instance_update(self, instance):
        pass

    @register_callback
    def post_instance_update(self, instance):
        pass

    def _output(self, *args, **kwargs):
        result = self.deserialize_output(self.ctx.vars.instance, client_flatten=True)
        return result

    class ClustersGet(AAZHttpOperation):
        CLIENT_TYPE = "MgmtClient"

        def __call__(self, *args, **kwargs):
            request = self.make_request()
            session = self.client.send_request(request=request, stream=False, **kwargs)
            if session.http_response.status_code in [200]:
                return self.on_200(session)

            return self.on_error(session.http_response)

        @property
        def url(self):
            return self.client.format_url(
                "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.HDInsight/clusterpools/{clusterPoolName}/clusters/{clusterName}",
                **self.url_parameters
            )

        @property
        def method(self):
            return "GET"

        @property
        def error_format(self):
            return "MgmtErrorFormat"

        @property
        def url_parameters(self):
            parameters = {
                **self.serialize_url_param(
                    "clusterName", self.ctx.args.cluster_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "clusterPoolName", self.ctx.args.cluster_pool_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "resourceGroupName", self.ctx.args.resource_group,
                    required=True,
                ),
                **self.serialize_url_param(
                    "subscriptionId", self.ctx.subscription_id,
                    required=True,
                ),
            }
            return parameters

        @property
        def query_parameters(self):
            parameters = {
                **self.serialize_query_param(
                    "api-version", "2023-06-01-preview",
                    required=True,
                ),
            }
            return parameters

        @property
        def header_parameters(self):
            parameters = {
                **self.serialize_header_param(
                    "Accept", "application/json",
                ),
            }
            return parameters

        def on_200(self, session):
            data = self.deserialize_http_content(session)
            self.ctx.set_var(
                "instance",
                data,
                schema_builder=self._build_schema_on_200
            )

        _schema_on_200 = None

        @classmethod
        def _build_schema_on_200(cls):
            if cls._schema_on_200 is not None:
                return cls._schema_on_200

            cls._schema_on_200 = AAZObjectType()
            _UpdateHelper._build_schema_cluster_read(cls._schema_on_200)

            return cls._schema_on_200

    class ClustersCreate(AAZHttpOperation):
        CLIENT_TYPE = "MgmtClient"

        def __call__(self, *args, **kwargs):
            request = self.make_request()
            session = self.client.send_request(request=request, stream=False, **kwargs)
            if session.http_response.status_code in [202]:
                return self.client.build_lro_polling(
                    self.ctx.args.no_wait,
                    session,
                    self.on_200_201,
                    self.on_error,
                    lro_options={"final-state-via": "azure-async-operation"},
                    path_format_arguments=self.url_parameters,
                )
            if session.http_response.status_code in [200, 201]:
                return self.client.build_lro_polling(
                    self.ctx.args.no_wait,
                    session,
                    self.on_200_201,
                    self.on_error,
                    lro_options={"final-state-via": "azure-async-operation"},
                    path_format_arguments=self.url_parameters,
                )

            return self.on_error(session.http_response)

        @property
        def url(self):
            return self.client.format_url(
                "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.HDInsight/clusterpools/{clusterPoolName}/clusters/{clusterName}",
                **self.url_parameters
            )

        @property
        def method(self):
            return "PUT"

        @property
        def error_format(self):
            return "MgmtErrorFormat"

        @property
        def url_parameters(self):
            parameters = {
                **self.serialize_url_param(
                    "clusterName", self.ctx.args.cluster_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "clusterPoolName", self.ctx.args.cluster_pool_name,
                    required=True,
                ),
                **self.serialize_url_param(
                    "resourceGroupName", self.ctx.args.resource_group,
                    required=True,
                ),
                **self.serialize_url_param(
                    "subscriptionId", self.ctx.subscription_id,
                    required=True,
                ),
            }
            return parameters

        @property
        def query_parameters(self):
            parameters = {
                **self.serialize_query_param(
                    "api-version", "2023-06-01-preview",
                    required=True,
                ),
            }
            return parameters

        @property
        def header_parameters(self):
            parameters = {
                **self.serialize_header_param(
                    "Content-Type", "application/json",
                ),
                **self.serialize_header_param(
                    "Accept", "application/json",
                ),
            }
            return parameters

        @property
        def content(self):
            _content_value, _builder = self.new_content_builder(
                self.ctx.args,
                value=self.ctx.vars.instance,
            )

            return self.serialize_content(_content_value)

        def on_200_201(self, session):
            data = self.deserialize_http_content(session)
            self.ctx.set_var(
                "instance",
                data,
                schema_builder=self._build_schema_on_200_201
            )

        _schema_on_200_201 = None

        @classmethod
        def _build_schema_on_200_201(cls):
            if cls._schema_on_200_201 is not None:
                return cls._schema_on_200_201

            cls._schema_on_200_201 = AAZObjectType()
            _UpdateHelper._build_schema_cluster_read(cls._schema_on_200_201)

            return cls._schema_on_200_201

    class InstanceUpdateByJson(AAZJsonInstanceUpdateOperation):

        def __call__(self, *args, **kwargs):
            self._update_instance(self.ctx.vars.instance)

        def _update_instance(self, instance):
            _instance_value, _builder = self.new_content_builder(
                self.ctx.args,
                value=instance,
                typ=AAZObjectType
            )
            _builder.set_prop("properties", AAZObjectType, typ_kwargs={"flags": {"client_flatten": True}})
            _builder.set_prop("tags", AAZDictType, ".tags")

            properties = _builder.get(".properties")
            if properties is not None:
                properties.set_prop("clusterProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                properties.set_prop("computeProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})

            cluster_profile = _builder.get(".properties.clusterProfile")
            if cluster_profile is not None:
                cluster_profile.set_prop("authorizationProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("autoscaleProfile", AAZObjectType)
                cluster_profile.set_prop("clusterVersion", AAZStrType, ".cluster_version", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("flinkProfile", AAZObjectType)
                cluster_profile.set_prop("identityProfile", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("kafkaProfile", AAZFreeFormDictType, ".kafka_profile")
                cluster_profile.set_prop("llapProfile", AAZFreeFormDictType, ".llap_profile")
                cluster_profile.set_prop("logAnalyticsProfile", AAZObjectType)
                cluster_profile.set_prop("ossVersion", AAZStrType, ".oss_version", typ_kwargs={"flags": {"required": True}})
                cluster_profile.set_prop("prometheusProfile", AAZObjectType)
                cluster_profile.set_prop("scriptActionProfiles", AAZListType, ".script_action_profiles")
                cluster_profile.set_prop("secretsProfile", AAZObjectType)
                cluster_profile.set_prop("serviceConfigsProfiles", AAZListType, ".service_configs_profiles")
                cluster_profile.set_prop("sparkProfile", AAZObjectType)
                cluster_profile.set_prop("sshProfile", AAZObjectType)
                cluster_profile.set_prop("stubProfile", AAZFreeFormDictType, ".stub_profile")
                cluster_profile.set_prop("trinoProfile", AAZObjectType, ".trino_profile")

            authorization_profile = _builder.get(".properties.clusterProfile.authorizationProfile")
            if authorization_profile is not None:
                authorization_profile.set_prop("groupIds", AAZListType, ".authorization_group_id")
                authorization_profile.set_prop("userIds", AAZListType, ".authorization_user_id")

            group_ids = _builder.get(".properties.clusterProfile.authorizationProfile.groupIds")
            if group_ids is not None:
                group_ids.set_elements(AAZStrType, ".")

            user_ids = _builder.get(".properties.clusterProfile.authorizationProfile.userIds")
            if user_ids is not None:
                user_ids.set_elements(AAZStrType, ".")

            autoscale_profile = _builder.get(".properties.clusterProfile.autoscaleProfile")
            if autoscale_profile is not None:
                autoscale_profile.set_prop("autoscaleType", AAZStrType, ".autoscale_profile_type")
                autoscale_profile.set_prop("enabled", AAZBoolType, ".autoscale_profile_enabled", typ_kwargs={"flags": {"required": True}})
                autoscale_profile.set_prop("gracefulDecommissionTimeout", AAZIntType, ".autoscale_profile_graceful_decommission_timeout")
                autoscale_profile.set_prop("loadBasedConfig", AAZObjectType)
                autoscale_profile.set_prop("scheduleBasedConfig", AAZObjectType)

            load_based_config = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig")
            if load_based_config is not None:
                load_based_config.set_prop("cooldownPeriod", AAZIntType, ".loadbased_config_cooldown_period")
                load_based_config.set_prop("maxNodes", AAZIntType, ".loadbased_config_max_nodes", typ_kwargs={"flags": {"required": True}})
                load_based_config.set_prop("minNodes", AAZIntType, ".loadbased_config_min_nodes", typ_kwargs={"flags": {"required": True}})
                load_based_config.set_prop("pollInterval", AAZIntType, ".loadbased_config_poll_interval")
                load_based_config.set_prop("scalingRules", AAZListType, ".loadbased_config_scaling_rules", typ_kwargs={"flags": {"required": True}})

            scaling_rules = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules")
            if scaling_rules is not None:
                scaling_rules.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules[]")
            if _elements is not None:
                _elements.set_prop("actionType", AAZStrType, ".action_type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("comparisonRule", AAZObjectType, ".comparison_rule", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("evaluationCount", AAZIntType, ".evaluation_count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("scalingMetric", AAZStrType, ".scaling_metric", typ_kwargs={"flags": {"required": True}})

            comparison_rule = _builder.get(".properties.clusterProfile.autoscaleProfile.loadBasedConfig.scalingRules[].comparisonRule")
            if comparison_rule is not None:
                comparison_rule.set_prop("operator", AAZStrType, ".operator", typ_kwargs={"flags": {"required": True}})
                comparison_rule.set_prop("threshold", AAZFloatType, ".threshold", typ_kwargs={"flags": {"required": True}})

            schedule_based_config = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig")
            if schedule_based_config is not None:
                schedule_based_config.set_prop("defaultCount", AAZIntType, ".schedule_based_config_default_count", typ_kwargs={"flags": {"required": True}})
                schedule_based_config.set_prop("schedules", AAZListType, ".schedule_based_config_schedule", typ_kwargs={"flags": {"required": True}})
                schedule_based_config.set_prop("timeZone", AAZStrType, ".schedule_based_config_time_zone", typ_kwargs={"flags": {"required": True}})

            schedules = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules")
            if schedules is not None:
                schedules.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules[]")
            if _elements is not None:
                _elements.set_prop("count", AAZIntType, ".count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("days", AAZListType, ".days", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("endTime", AAZStrType, ".end_time", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("startTime", AAZStrType, ".start_time", typ_kwargs={"flags": {"required": True}})

            days = _builder.get(".properties.clusterProfile.autoscaleProfile.scheduleBasedConfig.schedules[].days")
            if days is not None:
                days.set_elements(AAZStrType, ".")

            flink_profile = _builder.get(".properties.clusterProfile.flinkProfile")
            if flink_profile is not None:
                flink_profile.set_prop("catalogOptions", AAZObjectType)
                flink_profile.set_prop("historyServer", AAZObjectType)
                flink_profile.set_prop("jobManager", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                flink_profile.set_prop("numReplicas", AAZIntType, ".num_replicas")
                flink_profile.set_prop("storage", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})
                flink_profile.set_prop("taskManager", AAZObjectType, ".", typ_kwargs={"flags": {"required": True}})

            catalog_options = _builder.get(".properties.clusterProfile.flinkProfile.catalogOptions")
            if catalog_options is not None:
                catalog_options.set_prop("hive", AAZObjectType)

            hive = _builder.get(".properties.clusterProfile.flinkProfile.catalogOptions.hive")
            if hive is not None:
                hive.set_prop("metastoreDbConnectionPasswordSecret", AAZStrType, ".flink_hive_catalog_db_connection_password_secret", typ_kwargs={"flags": {"required": True}})
                hive.set_prop("metastoreDbConnectionURL", AAZStrType, ".flink_hive_catalog_db_connection_url", typ_kwargs={"flags": {"required": True}})
                hive.set_prop("metastoreDbConnectionUserName", AAZStrType, ".flink_hive_catalog_db_connection_user_name", typ_kwargs={"flags": {"required": True}})

            history_server = _builder.get(".properties.clusterProfile.flinkProfile.historyServer")
            if history_server is not None:
                history_server.set_prop("cpu", AAZFloatType, ".history_server_cpu", typ_kwargs={"flags": {"required": True}})
                history_server.set_prop("memory", AAZIntType, ".history_server_memory", typ_kwargs={"flags": {"required": True}})

            job_manager = _builder.get(".properties.clusterProfile.flinkProfile.jobManager")
            if job_manager is not None:
                job_manager.set_prop("cpu", AAZFloatType, ".job_manager_cpu", typ_kwargs={"flags": {"required": True}})
                job_manager.set_prop("memory", AAZIntType, ".job_manager_memory", typ_kwargs={"flags": {"required": True}})

            storage = _builder.get(".properties.clusterProfile.flinkProfile.storage")
            if storage is not None:
                storage.set_prop("storageUri", AAZStrType, ".flink_storage_uri", typ_kwargs={"flags": {"required": True}})
                storage.set_prop("storagekey", AAZStrType, ".flink_storage_key", typ_kwargs={"flags": {"secret": True}})

            task_manager = _builder.get(".properties.clusterProfile.flinkProfile.taskManager")
            if task_manager is not None:
                task_manager.set_prop("cpu", AAZFloatType, ".task_manager_cpu", typ_kwargs={"flags": {"required": True}})
                task_manager.set_prop("memory", AAZIntType, ".task_manager_memory", typ_kwargs={"flags": {"required": True}})

            identity_profile = _builder.get(".properties.clusterProfile.identityProfile")
            if identity_profile is not None:
                identity_profile.set_prop("msiClientId", AAZStrType, ".assigned_identity_client_id", typ_kwargs={"flags": {"required": True}})
                identity_profile.set_prop("msiObjectId", AAZStrType, ".assigned_identity_object_id", typ_kwargs={"flags": {"required": True}})
                identity_profile.set_prop("msiResourceId", AAZStrType, ".assigned_identity_resource_id", typ_kwargs={"flags": {"required": True}})

            kafka_profile = _builder.get(".properties.clusterProfile.kafkaProfile")
            if kafka_profile is not None:
                kafka_profile.set_anytype_elements(".")

            llap_profile = _builder.get(".properties.clusterProfile.llapProfile")
            if llap_profile is not None:
                llap_profile.set_anytype_elements(".")

            log_analytics_profile = _builder.get(".properties.clusterProfile.logAnalyticsProfile")
            if log_analytics_profile is not None:
                log_analytics_profile.set_prop("applicationLogs", AAZObjectType)
                log_analytics_profile.set_prop("enabled", AAZBoolType, ".enable_log_analytics", typ_kwargs={"flags": {"required": True}})
                log_analytics_profile.set_prop("metricsEnabled", AAZBoolType, ".log_analytic_profile_metrics_enabled")

            application_logs = _builder.get(".properties.clusterProfile.logAnalyticsProfile.applicationLogs")
            if application_logs is not None:
                application_logs.set_prop("stdErrorEnabled", AAZBoolType, ".application_log_std_error_enabled")
                application_logs.set_prop("stdOutEnabled", AAZBoolType, ".application_log_std_out_enabled")

            prometheus_profile = _builder.get(".properties.clusterProfile.prometheusProfile")
            if prometheus_profile is not None:
                prometheus_profile.set_prop("enabled", AAZBoolType, ".prometheu_profile_enabled", typ_kwargs={"flags": {"required": True}})

            script_action_profiles = _builder.get(".properties.clusterProfile.scriptActionProfiles")
            if script_action_profiles is not None:
                script_action_profiles.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.scriptActionProfiles[]")
            if _elements is not None:
                _elements.set_prop("name", AAZStrType, ".name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("parameters", AAZStrType, ".parameters")
                _elements.set_prop("services", AAZListType, ".services", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("shouldPersist", AAZBoolType, ".should_persist")
                _elements.set_prop("timeoutInMinutes", AAZIntType, ".timeout_in_minutes")
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("url", AAZStrType, ".url", typ_kwargs={"flags": {"required": True}})

            services = _builder.get(".properties.clusterProfile.scriptActionProfiles[].services")
            if services is not None:
                services.set_elements(AAZStrType, ".")

            secrets_profile = _builder.get(".properties.clusterProfile.secretsProfile")
            if secrets_profile is not None:
                secrets_profile.set_prop("keyVaultResourceId", AAZStrType, ".key_vault_id", typ_kwargs={"flags": {"required": True}})
                secrets_profile.set_prop("secrets", AAZListType, ".secret_reference")

            secrets = _builder.get(".properties.clusterProfile.secretsProfile.secrets")
            if secrets is not None:
                secrets.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.secretsProfile.secrets[]")
            if _elements is not None:
                _elements.set_prop("keyVaultObjectName", AAZStrType, ".secret_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("referenceName", AAZStrType, ".reference_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("version", AAZStrType, ".version")

            service_configs_profiles = _builder.get(".properties.clusterProfile.serviceConfigsProfiles")
            if service_configs_profiles is not None:
                service_configs_profiles.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[]")
            if _elements is not None:
                _elements.set_prop("configs", AAZListType, ".configs", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("serviceName", AAZStrType, ".service_name", typ_kwargs={"flags": {"required": True}})

            configs = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs")
            if configs is not None:
                configs.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[]")
            if _elements is not None:
                _elements.set_prop("component", AAZStrType, ".component", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("files", AAZListType, ".files", typ_kwargs={"flags": {"required": True}})

            files = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files")
            if files is not None:
                files.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files[]")
            if _elements is not None:
                _elements.set_prop("content", AAZStrType, ".content")
                _elements.set_prop("encoding", AAZStrType, ".encoding")
                _elements.set_prop("fileName", AAZStrType, ".file_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("path", AAZStrType, ".path")
                _elements.set_prop("values", AAZDictType, ".values")

            values = _builder.get(".properties.clusterProfile.serviceConfigsProfiles[].configs[].files[].values")
            if values is not None:
                values.set_elements(AAZStrType, ".")

            spark_profile = _builder.get(".properties.clusterProfile.sparkProfile")
            if spark_profile is not None:
                spark_profile.set_prop("defaultStorageUrl", AAZStrType, ".spark_storage_url")
                spark_profile.set_prop("metastoreSpec", AAZObjectType)
                spark_profile.set_prop("userPluginsSpec", AAZObjectType, ".user_plugins_spec")

            metastore_spec = _builder.get(".properties.clusterProfile.sparkProfile.metastoreSpec")
            if metastore_spec is not None:
                metastore_spec.set_prop("dbName", AAZStrType, ".spark_hive_catalog_db_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("dbPasswordSecretName", AAZStrType, ".spark_hive_catalog_db_password_secret_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("dbServerHost", AAZStrType, ".spark_hive_catalog_db_server_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("dbUserName", AAZStrType, ".spark_hive_catalog_db_user_name", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("keyVaultId", AAZStrType, ".spark_hive_catalog_key_vault_id", typ_kwargs={"flags": {"required": True}})
                metastore_spec.set_prop("thriftUrl", AAZStrType, ".spark_hive_catalog_thrift_url")

            user_plugins_spec = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec")
            if user_plugins_spec is not None:
                user_plugins_spec.set_prop("plugins", AAZListType, ".plugins")

            plugins = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec.plugins")
            if plugins is not None:
                plugins.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.sparkProfile.userPluginsSpec.plugins[]")
            if _elements is not None:
                _elements.set_prop("path", AAZStrType, ".path", typ_kwargs={"flags": {"required": True}})

            ssh_profile = _builder.get(".properties.clusterProfile.sshProfile")
            if ssh_profile is not None:
                ssh_profile.set_prop("count", AAZIntType, ".ssh_profile_count", typ_kwargs={"flags": {"required": True}})

            stub_profile = _builder.get(".properties.clusterProfile.stubProfile")
            if stub_profile is not None:
                stub_profile.set_anytype_elements(".")

            trino_profile = _builder.get(".properties.clusterProfile.trinoProfile")
            if trino_profile is not None:
                trino_profile.set_prop("catalogOptions", AAZObjectType, ".catalog_options")
                trino_profile.set_prop("coordinator", AAZObjectType)
                trino_profile.set_prop("userPluginsSpec", AAZObjectType, ".user_plugins_spec")
                trino_profile.set_prop("userTelemetrySpec", AAZObjectType, ".user_telemetry_spec")
                trino_profile.set_prop("worker", AAZObjectType, ".worker")

            catalog_options = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions")
            if catalog_options is not None:
                catalog_options.set_prop("hive", AAZListType, ".hive")

            hive = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions.hive")
            if hive is not None:
                hive.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.trinoProfile.catalogOptions.hive[]")
            if _elements is not None:
                _elements.set_prop("catalogName", AAZStrType, ".catalog_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreDbConnectionPasswordSecret", AAZStrType, ".metastore_db_connection_password_secret", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreDbConnectionURL", AAZStrType, ".metastore_db_connection_url", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreDbConnectionUserName", AAZStrType, ".metastore_db_connection_user_name", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("metastoreWarehouseDir", AAZStrType, ".metastore_warehouse_dir", typ_kwargs={"flags": {"required": True}})

            coordinator = _builder.get(".properties.clusterProfile.trinoProfile.coordinator")
            if coordinator is not None:
                coordinator.set_prop("debug", AAZObjectType, typ_kwargs={"flags": {"client_flatten": True}})
                coordinator.set_prop("highAvailabilityEnabled", AAZBoolType, ".coordinator_debug_enabled")

            debug = _builder.get(".properties.clusterProfile.trinoProfile.coordinator.debug")
            if debug is not None:
                debug.set_prop("enable", AAZBoolType, ".coordinator_high_availability_enabled")
                debug.set_prop("port", AAZIntType, ".coordinator_debug_port")
                debug.set_prop("suspend", AAZBoolType, ".coordinator_debug_suspend")

            user_plugins_spec = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec")
            if user_plugins_spec is not None:
                user_plugins_spec.set_prop("plugins", AAZListType, ".plugins")

            plugins = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec.plugins")
            if plugins is not None:
                plugins.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.clusterProfile.trinoProfile.userPluginsSpec.plugins[]")
            if _elements is not None:
                _elements.set_prop("enabled", AAZBoolType, ".enabled")
                _elements.set_prop("name", AAZStrType, ".name")
                _elements.set_prop("path", AAZStrType, ".path")

            user_telemetry_spec = _builder.get(".properties.clusterProfile.trinoProfile.userTelemetrySpec")
            if user_telemetry_spec is not None:
                user_telemetry_spec.set_prop("storage", AAZObjectType, ".storage")

            storage = _builder.get(".properties.clusterProfile.trinoProfile.userTelemetrySpec.storage")
            if storage is not None:
                storage.set_prop("hivecatalogName", AAZStrType, ".hivecatalog_name")
                storage.set_prop("hivecatalogSchema", AAZStrType, ".hivecatalog_schema")
                storage.set_prop("partitionRetentionInDays", AAZIntType, ".partition_retention_in_days")
                storage.set_prop("path", AAZStrType, ".path")

            worker = _builder.get(".properties.clusterProfile.trinoProfile.worker")
            if worker is not None:
                _UpdateHelper._build_schema_trino_debug_config_update(worker.set_prop("debug", AAZObjectType, ".debug", typ_kwargs={"flags": {"client_flatten": True}}))

            compute_profile = _builder.get(".properties.computeProfile")
            if compute_profile is not None:
                compute_profile.set_prop("nodes", AAZListType, ".nodes", typ_kwargs={"flags": {"required": True}})

            nodes = _builder.get(".properties.computeProfile.nodes")
            if nodes is not None:
                nodes.set_elements(AAZObjectType, ".")

            _elements = _builder.get(".properties.computeProfile.nodes[]")
            if _elements is not None:
                _elements.set_prop("count", AAZIntType, ".count", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("type", AAZStrType, ".type", typ_kwargs={"flags": {"required": True}})
                _elements.set_prop("vmSize", AAZStrType, ".vm_size", typ_kwargs={"flags": {"required": True}})

            tags = _builder.get(".tags")
            if tags is not None:
                tags.set_elements(AAZStrType, ".")

            return _instance_value

    class InstanceUpdateByGeneric(AAZGenericInstanceUpdateOperation):

        def __call__(self, *args, **kwargs):
            self._update_instance_by_generic(
                self.ctx.vars.instance,
                self.ctx.generic_update_args
            )


class _UpdateHelper:
    """Helper class for Update"""

    @classmethod
    def _build_schema_trino_debug_config_update(cls, _builder):
        if _builder is None:
            return
        _builder.set_prop("enable", AAZBoolType, ".enable")
        _builder.set_prop("port", AAZIntType, ".port")
        _builder.set_prop("suspend", AAZBoolType, ".suspend")

    _schema_cluster_read = None

    @classmethod
    def _build_schema_cluster_read(cls, _schema):
        if cls._schema_cluster_read is not None:
            _schema.id = cls._schema_cluster_read.id
            _schema.location = cls._schema_cluster_read.location
            _schema.name = cls._schema_cluster_read.name
            _schema.properties = cls._schema_cluster_read.properties
            _schema.system_data = cls._schema_cluster_read.system_data
            _schema.tags = cls._schema_cluster_read.tags
            _schema.type = cls._schema_cluster_read.type
            return

        cls._schema_cluster_read = _schema_cluster_read = AAZObjectType()

        cluster_read = _schema_cluster_read
        cluster_read.id = AAZStrType(
            flags={"read_only": True},
        )
        cluster_read.location = AAZStrType(
            flags={"required": True},
        )
        cluster_read.name = AAZStrType(
            flags={"read_only": True},
        )
        cluster_read.properties = AAZObjectType(
            flags={"client_flatten": True},
        )
        cluster_read.system_data = AAZObjectType(
            serialized_name="systemData",
            flags={"read_only": True},
        )
        cluster_read.tags = AAZDictType()
        cluster_read.type = AAZStrType(
            flags={"read_only": True},
        )

        properties = _schema_cluster_read.properties
        properties.cluster_profile = AAZObjectType(
            serialized_name="clusterProfile",
            flags={"required": True},
        )
        properties.cluster_type = AAZStrType(
            serialized_name="clusterType",
            flags={"required": True},
        )
        properties.compute_profile = AAZObjectType(
            serialized_name="computeProfile",
            flags={"required": True},
        )
        properties.deployment_id = AAZStrType(
            serialized_name="deploymentId",
            flags={"read_only": True},
        )
        properties.provisioning_state = AAZStrType(
            serialized_name="provisioningState",
            flags={"read_only": True},
        )
        properties.status = AAZStrType(
            flags={"read_only": True},
        )

        cluster_profile = _schema_cluster_read.properties.cluster_profile
        cluster_profile.authorization_profile = AAZObjectType(
            serialized_name="authorizationProfile",
            flags={"required": True},
        )
        cluster_profile.autoscale_profile = AAZObjectType(
            serialized_name="autoscaleProfile",
        )
        cluster_profile.cluster_version = AAZStrType(
            serialized_name="clusterVersion",
            flags={"required": True},
        )
        cluster_profile.components = AAZListType(
            flags={"read_only": True},
        )
        cluster_profile.connectivity_profile = AAZObjectType(
            serialized_name="connectivityProfile",
            flags={"read_only": True},
        )
        cluster_profile.flink_profile = AAZObjectType(
            serialized_name="flinkProfile",
        )
        cluster_profile.identity_profile = AAZObjectType(
            serialized_name="identityProfile",
            flags={"required": True},
        )
        cluster_profile.kafka_profile = AAZFreeFormDictType(
            serialized_name="kafkaProfile",
        )
        cluster_profile.llap_profile = AAZFreeFormDictType(
            serialized_name="llapProfile",
        )
        cluster_profile.log_analytics_profile = AAZObjectType(
            serialized_name="logAnalyticsProfile",
        )
        cluster_profile.oss_version = AAZStrType(
            serialized_name="ossVersion",
            flags={"required": True},
        )
        cluster_profile.prometheus_profile = AAZObjectType(
            serialized_name="prometheusProfile",
        )
        cluster_profile.script_action_profiles = AAZListType(
            serialized_name="scriptActionProfiles",
        )
        cluster_profile.secrets_profile = AAZObjectType(
            serialized_name="secretsProfile",
        )
        cluster_profile.service_configs_profiles = AAZListType(
            serialized_name="serviceConfigsProfiles",
        )
        cluster_profile.spark_profile = AAZObjectType(
            serialized_name="sparkProfile",
        )
        cluster_profile.ssh_profile = AAZObjectType(
            serialized_name="sshProfile",
        )
        cluster_profile.stub_profile = AAZFreeFormDictType(
            serialized_name="stubProfile",
        )
        cluster_profile.trino_profile = AAZObjectType(
            serialized_name="trinoProfile",
        )

        authorization_profile = _schema_cluster_read.properties.cluster_profile.authorization_profile
        authorization_profile.group_ids = AAZListType(
            serialized_name="groupIds",
        )
        authorization_profile.user_ids = AAZListType(
            serialized_name="userIds",
        )

        group_ids = _schema_cluster_read.properties.cluster_profile.authorization_profile.group_ids
        group_ids.Element = AAZStrType()

        user_ids = _schema_cluster_read.properties.cluster_profile.authorization_profile.user_ids
        user_ids.Element = AAZStrType()

        autoscale_profile = _schema_cluster_read.properties.cluster_profile.autoscale_profile
        autoscale_profile.autoscale_type = AAZStrType(
            serialized_name="autoscaleType",
        )
        autoscale_profile.enabled = AAZBoolType(
            flags={"required": True},
        )
        autoscale_profile.graceful_decommission_timeout = AAZIntType(
            serialized_name="gracefulDecommissionTimeout",
        )
        autoscale_profile.load_based_config = AAZObjectType(
            serialized_name="loadBasedConfig",
        )
        autoscale_profile.schedule_based_config = AAZObjectType(
            serialized_name="scheduleBasedConfig",
        )

        load_based_config = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config
        load_based_config.cooldown_period = AAZIntType(
            serialized_name="cooldownPeriod",
        )
        load_based_config.max_nodes = AAZIntType(
            serialized_name="maxNodes",
            flags={"required": True},
        )
        load_based_config.min_nodes = AAZIntType(
            serialized_name="minNodes",
            flags={"required": True},
        )
        load_based_config.poll_interval = AAZIntType(
            serialized_name="pollInterval",
        )
        load_based_config.scaling_rules = AAZListType(
            serialized_name="scalingRules",
            flags={"required": True},
        )

        scaling_rules = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules
        scaling_rules.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules.Element
        _element.action_type = AAZStrType(
            serialized_name="actionType",
            flags={"required": True},
        )
        _element.comparison_rule = AAZObjectType(
            serialized_name="comparisonRule",
            flags={"required": True},
        )
        _element.evaluation_count = AAZIntType(
            serialized_name="evaluationCount",
            flags={"required": True},
        )
        _element.scaling_metric = AAZStrType(
            serialized_name="scalingMetric",
            flags={"required": True},
        )

        comparison_rule = _schema_cluster_read.properties.cluster_profile.autoscale_profile.load_based_config.scaling_rules.Element.comparison_rule
        comparison_rule.operator = AAZStrType(
            flags={"required": True},
        )
        comparison_rule.threshold = AAZFloatType(
            flags={"required": True},
        )

        schedule_based_config = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config
        schedule_based_config.default_count = AAZIntType(
            serialized_name="defaultCount",
            flags={"required": True},
        )
        schedule_based_config.schedules = AAZListType(
            flags={"required": True},
        )
        schedule_based_config.time_zone = AAZStrType(
            serialized_name="timeZone",
            flags={"required": True},
        )

        schedules = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules
        schedules.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules.Element
        _element.count = AAZIntType(
            flags={"required": True},
        )
        _element.days = AAZListType(
            flags={"required": True},
        )
        _element.end_time = AAZStrType(
            serialized_name="endTime",
            flags={"required": True},
        )
        _element.start_time = AAZStrType(
            serialized_name="startTime",
            flags={"required": True},
        )

        days = _schema_cluster_read.properties.cluster_profile.autoscale_profile.schedule_based_config.schedules.Element.days
        days.Element = AAZStrType()

        components = _schema_cluster_read.properties.cluster_profile.components
        components.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.components.Element
        _element.name = AAZStrType()
        _element.version = AAZStrType()

        connectivity_profile = _schema_cluster_read.properties.cluster_profile.connectivity_profile
        connectivity_profile.ssh = AAZListType()
        connectivity_profile.web = AAZObjectType(
            flags={"required": True},
        )

        ssh = _schema_cluster_read.properties.cluster_profile.connectivity_profile.ssh
        ssh.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.connectivity_profile.ssh.Element
        _element.endpoint = AAZStrType(
            flags={"required": True},
        )

        web = _schema_cluster_read.properties.cluster_profile.connectivity_profile.web
        web.fqdn = AAZStrType(
            flags={"required": True},
        )

        flink_profile = _schema_cluster_read.properties.cluster_profile.flink_profile
        flink_profile.catalog_options = AAZObjectType(
            serialized_name="catalogOptions",
        )
        flink_profile.history_server = AAZObjectType(
            serialized_name="historyServer",
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.history_server)
        flink_profile.job_manager = AAZObjectType(
            serialized_name="jobManager",
            flags={"required": True},
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.job_manager)
        flink_profile.num_replicas = AAZIntType(
            serialized_name="numReplicas",
        )
        flink_profile.storage = AAZObjectType(
            flags={"required": True},
        )
        flink_profile.task_manager = AAZObjectType(
            serialized_name="taskManager",
            flags={"required": True},
        )
        cls._build_schema_compute_resource_definition_read(flink_profile.task_manager)

        catalog_options = _schema_cluster_read.properties.cluster_profile.flink_profile.catalog_options
        catalog_options.hive = AAZObjectType()

        hive = _schema_cluster_read.properties.cluster_profile.flink_profile.catalog_options.hive
        hive.metastore_db_connection_password_secret = AAZStrType(
            serialized_name="metastoreDbConnectionPasswordSecret",
            flags={"required": True},
        )
        hive.metastore_db_connection_url = AAZStrType(
            serialized_name="metastoreDbConnectionURL",
            flags={"required": True},
        )
        hive.metastore_db_connection_user_name = AAZStrType(
            serialized_name="metastoreDbConnectionUserName",
            flags={"required": True},
        )

        storage = _schema_cluster_read.properties.cluster_profile.flink_profile.storage
        storage.storage_uri = AAZStrType(
            serialized_name="storageUri",
            flags={"required": True},
        )
        storage.storagekey = AAZStrType(
            flags={"secret": True},
        )

        identity_profile = _schema_cluster_read.properties.cluster_profile.identity_profile
        identity_profile.msi_client_id = AAZStrType(
            serialized_name="msiClientId",
            flags={"required": True},
        )
        identity_profile.msi_object_id = AAZStrType(
            serialized_name="msiObjectId",
            flags={"required": True},
        )
        identity_profile.msi_resource_id = AAZStrType(
            serialized_name="msiResourceId",
            flags={"required": True},
        )

        log_analytics_profile = _schema_cluster_read.properties.cluster_profile.log_analytics_profile
        log_analytics_profile.application_logs = AAZObjectType(
            serialized_name="applicationLogs",
        )
        log_analytics_profile.enabled = AAZBoolType(
            flags={"required": True},
        )
        log_analytics_profile.metrics_enabled = AAZBoolType(
            serialized_name="metricsEnabled",
        )

        application_logs = _schema_cluster_read.properties.cluster_profile.log_analytics_profile.application_logs
        application_logs.std_error_enabled = AAZBoolType(
            serialized_name="stdErrorEnabled",
        )
        application_logs.std_out_enabled = AAZBoolType(
            serialized_name="stdOutEnabled",
        )

        prometheus_profile = _schema_cluster_read.properties.cluster_profile.prometheus_profile
        prometheus_profile.enabled = AAZBoolType(
            flags={"required": True},
        )

        script_action_profiles = _schema_cluster_read.properties.cluster_profile.script_action_profiles
        script_action_profiles.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.script_action_profiles.Element
        _element.name = AAZStrType(
            flags={"required": True},
        )
        _element.parameters = AAZStrType()
        _element.services = AAZListType(
            flags={"required": True},
        )
        _element.should_persist = AAZBoolType(
            serialized_name="shouldPersist",
        )
        _element.timeout_in_minutes = AAZIntType(
            serialized_name="timeoutInMinutes",
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.url = AAZStrType(
            flags={"required": True},
        )

        services = _schema_cluster_read.properties.cluster_profile.script_action_profiles.Element.services
        services.Element = AAZStrType()

        secrets_profile = _schema_cluster_read.properties.cluster_profile.secrets_profile
        secrets_profile.key_vault_resource_id = AAZStrType(
            serialized_name="keyVaultResourceId",
            flags={"required": True},
        )
        secrets_profile.secrets = AAZListType()

        secrets = _schema_cluster_read.properties.cluster_profile.secrets_profile.secrets
        secrets.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.secrets_profile.secrets.Element
        _element.key_vault_object_name = AAZStrType(
            serialized_name="keyVaultObjectName",
            flags={"required": True},
        )
        _element.reference_name = AAZStrType(
            serialized_name="referenceName",
            flags={"required": True},
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.version = AAZStrType()

        service_configs_profiles = _schema_cluster_read.properties.cluster_profile.service_configs_profiles
        service_configs_profiles.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element
        _element.configs = AAZListType(
            flags={"required": True},
        )
        _element.service_name = AAZStrType(
            serialized_name="serviceName",
            flags={"required": True},
        )

        configs = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs
        configs.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element
        _element.component = AAZStrType(
            flags={"required": True},
        )
        _element.files = AAZListType(
            flags={"required": True},
        )

        files = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files
        files.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files.Element
        _element.content = AAZStrType()
        _element.encoding = AAZStrType()
        _element.file_name = AAZStrType(
            serialized_name="fileName",
            flags={"required": True},
        )
        _element.path = AAZStrType()
        _element.values = AAZDictType()

        values = _schema_cluster_read.properties.cluster_profile.service_configs_profiles.Element.configs.Element.files.Element.values
        values.Element = AAZStrType()

        spark_profile = _schema_cluster_read.properties.cluster_profile.spark_profile
        spark_profile.default_storage_url = AAZStrType(
            serialized_name="defaultStorageUrl",
        )
        spark_profile.metastore_spec = AAZObjectType(
            serialized_name="metastoreSpec",
        )
        spark_profile.user_plugins_spec = AAZObjectType(
            serialized_name="userPluginsSpec",
        )

        metastore_spec = _schema_cluster_read.properties.cluster_profile.spark_profile.metastore_spec
        metastore_spec.db_name = AAZStrType(
            serialized_name="dbName",
            flags={"required": True},
        )
        metastore_spec.db_password_secret_name = AAZStrType(
            serialized_name="dbPasswordSecretName",
            flags={"required": True},
        )
        metastore_spec.db_server_host = AAZStrType(
            serialized_name="dbServerHost",
            flags={"required": True},
        )
        metastore_spec.db_user_name = AAZStrType(
            serialized_name="dbUserName",
            flags={"required": True},
        )
        metastore_spec.key_vault_id = AAZStrType(
            serialized_name="keyVaultId",
            flags={"required": True},
        )
        metastore_spec.thrift_url = AAZStrType(
            serialized_name="thriftUrl",
        )

        user_plugins_spec = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec
        user_plugins_spec.plugins = AAZListType()

        plugins = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec.plugins
        plugins.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.spark_profile.user_plugins_spec.plugins.Element
        _element.path = AAZStrType(
            flags={"required": True},
        )

        ssh_profile = _schema_cluster_read.properties.cluster_profile.ssh_profile
        ssh_profile.count = AAZIntType(
            flags={"required": True},
        )
        ssh_profile.pod_prefix = AAZStrType(
            serialized_name="podPrefix",
            flags={"read_only": True},
        )

        trino_profile = _schema_cluster_read.properties.cluster_profile.trino_profile
        trino_profile.catalog_options = AAZObjectType(
            serialized_name="catalogOptions",
        )
        trino_profile.coordinator = AAZObjectType()
        trino_profile.user_plugins_spec = AAZObjectType(
            serialized_name="userPluginsSpec",
        )
        trino_profile.user_telemetry_spec = AAZObjectType(
            serialized_name="userTelemetrySpec",
        )
        trino_profile.worker = AAZObjectType()

        catalog_options = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options
        catalog_options.hive = AAZListType()

        hive = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options.hive
        hive.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.trino_profile.catalog_options.hive.Element
        _element.catalog_name = AAZStrType(
            serialized_name="catalogName",
            flags={"required": True},
        )
        _element.metastore_db_connection_password_secret = AAZStrType(
            serialized_name="metastoreDbConnectionPasswordSecret",
            flags={"required": True},
        )
        _element.metastore_db_connection_url = AAZStrType(
            serialized_name="metastoreDbConnectionURL",
            flags={"required": True},
        )
        _element.metastore_db_connection_user_name = AAZStrType(
            serialized_name="metastoreDbConnectionUserName",
            flags={"required": True},
        )
        _element.metastore_warehouse_dir = AAZStrType(
            serialized_name="metastoreWarehouseDir",
            flags={"required": True},
        )

        coordinator = _schema_cluster_read.properties.cluster_profile.trino_profile.coordinator
        coordinator.debug = AAZObjectType(
            flags={"client_flatten": True},
        )
        cls._build_schema_trino_debug_config_read(coordinator.debug)
        coordinator.high_availability_enabled = AAZBoolType(
            serialized_name="highAvailabilityEnabled",
        )

        user_plugins_spec = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec
        user_plugins_spec.plugins = AAZListType()

        plugins = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec.plugins
        plugins.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.cluster_profile.trino_profile.user_plugins_spec.plugins.Element
        _element.enabled = AAZBoolType()
        _element.name = AAZStrType()
        _element.path = AAZStrType()

        user_telemetry_spec = _schema_cluster_read.properties.cluster_profile.trino_profile.user_telemetry_spec
        user_telemetry_spec.storage = AAZObjectType()

        storage = _schema_cluster_read.properties.cluster_profile.trino_profile.user_telemetry_spec.storage
        storage.hivecatalog_name = AAZStrType(
            serialized_name="hivecatalogName",
        )
        storage.hivecatalog_schema = AAZStrType(
            serialized_name="hivecatalogSchema",
        )
        storage.partition_retention_in_days = AAZIntType(
            serialized_name="partitionRetentionInDays",
        )
        storage.path = AAZStrType()

        worker = _schema_cluster_read.properties.cluster_profile.trino_profile.worker
        worker.debug = AAZObjectType(
            flags={"client_flatten": True},
        )
        cls._build_schema_trino_debug_config_read(worker.debug)

        compute_profile = _schema_cluster_read.properties.compute_profile
        compute_profile.nodes = AAZListType(
            flags={"required": True},
        )

        nodes = _schema_cluster_read.properties.compute_profile.nodes
        nodes.Element = AAZObjectType()

        _element = _schema_cluster_read.properties.compute_profile.nodes.Element
        _element.count = AAZIntType(
            flags={"required": True},
        )
        _element.type = AAZStrType(
            flags={"required": True},
        )
        _element.vm_size = AAZStrType(
            serialized_name="vmSize",
            flags={"required": True},
        )

        system_data = _schema_cluster_read.system_data
        system_data.created_at = AAZStrType(
            serialized_name="createdAt",
        )
        system_data.created_by = AAZStrType(
            serialized_name="createdBy",
        )
        system_data.created_by_type = AAZStrType(
            serialized_name="createdByType",
        )
        system_data.last_modified_at = AAZStrType(
            serialized_name="lastModifiedAt",
        )
        system_data.last_modified_by = AAZStrType(
            serialized_name="lastModifiedBy",
        )
        system_data.last_modified_by_type = AAZStrType(
            serialized_name="lastModifiedByType",
        )

        tags = _schema_cluster_read.tags
        tags.Element = AAZStrType()

        _schema.id = cls._schema_cluster_read.id
        _schema.location = cls._schema_cluster_read.location
        _schema.name = cls._schema_cluster_read.name
        _schema.properties = cls._schema_cluster_read.properties
        _schema.system_data = cls._schema_cluster_read.system_data
        _schema.tags = cls._schema_cluster_read.tags
        _schema.type = cls._schema_cluster_read.type

    _schema_compute_resource_definition_read = None

    @classmethod
    def _build_schema_compute_resource_definition_read(cls, _schema):
        if cls._schema_compute_resource_definition_read is not None:
            _schema.cpu = cls._schema_compute_resource_definition_read.cpu
            _schema.memory = cls._schema_compute_resource_definition_read.memory
            return

        cls._schema_compute_resource_definition_read = _schema_compute_resource_definition_read = AAZObjectType()

        compute_resource_definition_read = _schema_compute_resource_definition_read
        compute_resource_definition_read.cpu = AAZFloatType(
            flags={"required": True},
        )
        compute_resource_definition_read.memory = AAZIntType(
            flags={"required": True},
        )

        _schema.cpu = cls._schema_compute_resource_definition_read.cpu
        _schema.memory = cls._schema_compute_resource_definition_read.memory

    _schema_trino_debug_config_read = None

    @classmethod
    def _build_schema_trino_debug_config_read(cls, _schema):
        if cls._schema_trino_debug_config_read is not None:
            _schema.enable = cls._schema_trino_debug_config_read.enable
            _schema.port = cls._schema_trino_debug_config_read.port
            _schema.suspend = cls._schema_trino_debug_config_read.suspend
            return

        cls._schema_trino_debug_config_read = _schema_trino_debug_config_read = AAZObjectType()

        trino_debug_config_read = _schema_trino_debug_config_read
        trino_debug_config_read.enable = AAZBoolType()
        trino_debug_config_read.port = AAZIntType()
        trino_debug_config_read.suspend = AAZBoolType()

        _schema.enable = cls._schema_trino_debug_config_read.enable
        _schema.port = cls._schema_trino_debug_config_read.port
        _schema.suspend = cls._schema_trino_debug_config_read.suspend


__all__ = ["Update"]
